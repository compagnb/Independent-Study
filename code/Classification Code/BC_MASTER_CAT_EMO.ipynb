{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np #import numpy library\n",
    "import pandas as pd #import pandas library\n",
    "import matplotlib.pyplot as plt #import matplot library\n",
    "%matplotlib inline\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import nltk.classify.util\n",
    "from astropy.table import Table, Column\n",
    "\n",
    "import string\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " def loadMetricData(user, directory):\n",
    "    path =  user + \"/\" + directory + \"/\"\n",
    "#     print(path)\n",
    "    all_files = glob.glob(os.path.join(path, \"*.csv\")) \n",
    "#     print(all_files)\n",
    "    data = pd.DataFrame()\n",
    "    list_ = []\n",
    "    for file_ in all_files:\n",
    "        data = pd.read_csv(file_,index_col=None, header=0)\n",
    "        list_.append(data)\n",
    "        data = pd.concat(list_)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # clean times function\n",
    "def cleanTime(df, col):\n",
    "    df.col = pd.to_datetime(df.col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>steps</th>\n",
       "      <th>calories</th>\n",
       "      <th>gsr</th>\n",
       "      <th>skintemp</th>\n",
       "      <th>airtemp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>2016-05-02 23:55:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>2016-05-02 23:56:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>2016-05-02 23:57:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>2016-05-02 23:58:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>2016-05-02 23:59:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp  heartrate  steps  calories  gsr  skintemp  airtemp\n",
       "1435  2016-05-02 23:55:00        NaN    NaN       NaN  NaN       NaN      NaN\n",
       "1436  2016-05-02 23:56:00        NaN    NaN       NaN  NaN       NaN      NaN\n",
       "1437  2016-05-02 23:57:00        NaN    NaN       NaN  NaN       NaN      NaN\n",
       "1438  2016-05-02 23:58:00        NaN    NaN       NaN  NaN       NaN      NaN\n",
       "1439  2016-05-02 23:59:00        NaN    NaN       NaN  NaN       NaN      NaN"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = loadMetricData('barbComp', \"metrics\")\n",
    "metrics.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp     object\n",
       "heartrate    float64\n",
       "steps        float64\n",
       "calories     float64\n",
       "gsr          float64\n",
       "skintemp     float64\n",
       "airtemp      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean metric data\n",
    "\n",
    "metrics.timestamp = pd.to_datetime(metrics.timestamp)\n",
    "\n",
    "metrics.heartrate = metrics.heartrate.fillna(0)\n",
    "metrics.steps = metrics.steps.fillna(0)\n",
    "metrics.calories = metrics.calories.fillna(0)\n",
    "metrics.gsr = metrics.gsr.fillna(0)\n",
    "metrics.skintemp = metrics.skintemp.fillna(0)\n",
    "metrics.airtemp = metrics.airtemp.fillna(0)\n",
    "\n",
    "# metrics.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# metrics = metrics[metrics.heartrate != 0]\n",
    "# metrics.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "activities = loadMetricData('barbComp', \"activities\")\n",
    "# activities.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sleep = loadMetricData('barbComp', \"sleep\")\n",
    "# sleep.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sleep.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "journal = loadMetricData('barbComp', \"journal\")\n",
    "# journal.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# journal.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starttime</th>\n",
       "      <th>endtime</th>\n",
       "      <th>date</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>activity</th>\n",
       "      <th>location</th>\n",
       "      <th>generalemo</th>\n",
       "      <th>qualitative</th>\n",
       "      <th>excited</th>\n",
       "      <th>...</th>\n",
       "      <th>angry</th>\n",
       "      <th>hungry</th>\n",
       "      <th>tired</th>\n",
       "      <th>bored</th>\n",
       "      <th>exhaca</th>\n",
       "      <th>ansaan</th>\n",
       "      <th>exha</th>\n",
       "      <th>haca</th>\n",
       "      <th>anan</th>\n",
       "      <th>ansa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-26 09:28:00</td>\n",
       "      <td>2016-04-26 09:33:00</td>\n",
       "      <td>4/26/16</td>\n",
       "      <td>9:28 AM</td>\n",
       "      <td>9:33 AM</td>\n",
       "      <td>setting up basis, drinking coffee, listening t...</td>\n",
       "      <td>work</td>\n",
       "      <td>Calm</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-04-26 09:33:00</td>\n",
       "      <td>2016-04-26 10:02:00</td>\n",
       "      <td>4/26/16</td>\n",
       "      <td>9:33 AM</td>\n",
       "      <td>10:02 AM</td>\n",
       "      <td>listening to 80's pop, going through work email</td>\n",
       "      <td>work</td>\n",
       "      <td>Calm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-04-26 10:02:00</td>\n",
       "      <td>2016-04-26 10:25:00</td>\n",
       "      <td>4/26/16</td>\n",
       "      <td>10:02 AM</td>\n",
       "      <td>10:25 AM</td>\n",
       "      <td>meeting with student</td>\n",
       "      <td>work</td>\n",
       "      <td>Calm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-04-26 10:25:00</td>\n",
       "      <td>2016-04-26 10:35:00</td>\n",
       "      <td>4/26/16</td>\n",
       "      <td>10:25 AM</td>\n",
       "      <td>10:35 AM</td>\n",
       "      <td>meeting with mick</td>\n",
       "      <td>work</td>\n",
       "      <td>Calm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-04-26 10:35:00</td>\n",
       "      <td>2016-04-26 10:45:00</td>\n",
       "      <td>4/26/16</td>\n",
       "      <td>10:35 AM</td>\n",
       "      <td>10:45 AM</td>\n",
       "      <td>meeting with student</td>\n",
       "      <td>school</td>\n",
       "      <td>Calm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            starttime             endtime     date     start       end  \\\n",
       "0 2016-04-26 09:28:00 2016-04-26 09:33:00  4/26/16   9:28 AM   9:33 AM   \n",
       "1 2016-04-26 09:33:00 2016-04-26 10:02:00  4/26/16   9:33 AM  10:02 AM   \n",
       "2 2016-04-26 10:02:00 2016-04-26 10:25:00  4/26/16  10:02 AM  10:25 AM   \n",
       "3 2016-04-26 10:25:00 2016-04-26 10:35:00  4/26/16  10:25 AM  10:35 AM   \n",
       "4 2016-04-26 10:35:00 2016-04-26 10:45:00  4/26/16  10:35 AM  10:45 AM   \n",
       "\n",
       "                                            activity location generalemo  \\\n",
       "0  setting up basis, drinking coffee, listening t...     work       Calm   \n",
       "1    listening to 80's pop, going through work email     work       Calm   \n",
       "2                               meeting with student     work       Calm   \n",
       "3                                  meeting with mick     work       Calm   \n",
       "4                               meeting with student   school       Calm   \n",
       "\n",
       "   qualitative  excited  ...   angry  hungry  tired  bored  exhaca  ansaan  \\\n",
       "0            0        1  ...       0       0      2      1       9       0   \n",
       "1            0        0  ...       0       0      2      0       8       0   \n",
       "2            0        0  ...       0       0      4      0       6       0   \n",
       "3            0        0  ...       0       0      4      0       6       0   \n",
       "4            0        0  ...       0       0      4      0       6       0   \n",
       "\n",
       "   exha  haca  anan  ansa  \n",
       "0     3     8     0     0  \n",
       "1     2     8     0     0  \n",
       "2     0     6     0     0  \n",
       "3     0     6     0     0  \n",
       "4     0     6     0     0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean metric data\n",
    "journal.starttime= pd.to_datetime(journal.starttime)\n",
    "journal.endtime= pd.to_datetime(journal.endtime)\n",
    "\n",
    "journal.qualitative = journal.qualitative.fillna(0)\n",
    "journal.excited = journal.excited.fillna(0)\n",
    "journal.happy = journal.happy.fillna(0)\n",
    "journal.calm = journal.calm.fillna(0)\n",
    "journal.anxious = journal.anxious.fillna(0)\n",
    "journal.sad = journal.sad.fillna(0)\n",
    "journal.angry = journal.angry.fillna(0)\n",
    "journal.hungry = journal.hungry.fillna(0)\n",
    "journal.tired = journal.tired.fillna(0)\n",
    "journal.bored = journal.bored.fillna(0)\n",
    "journal.ansaan = journal.ansaan.fillna(0)\n",
    "journal.exhaca = journal.exhaca.fillna(0)\n",
    "\n",
    "print(journal.shape)\n",
    "journal.head(5)\n",
    "# journal.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starttime</th>\n",
       "      <th>endtime</th>\n",
       "      <th>date</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>activity</th>\n",
       "      <th>location</th>\n",
       "      <th>generalemo</th>\n",
       "      <th>qualitative</th>\n",
       "      <th>excited</th>\n",
       "      <th>...</th>\n",
       "      <th>ansa</th>\n",
       "      <th>boolexcited</th>\n",
       "      <th>boolhappy</th>\n",
       "      <th>boolcalm</th>\n",
       "      <th>boolanxious</th>\n",
       "      <th>boolsad</th>\n",
       "      <th>boolangry</th>\n",
       "      <th>booltired</th>\n",
       "      <th>boolhungry</th>\n",
       "      <th>boolbored</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-26 09:28:00</td>\n",
       "      <td>2016-04-26 09:33:00</td>\n",
       "      <td>4/26/16</td>\n",
       "      <td>9:28 AM</td>\n",
       "      <td>9:33 AM</td>\n",
       "      <td>setting up basis, drinking coffee, listening t...</td>\n",
       "      <td>work</td>\n",
       "      <td>Calm</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-04-26 09:33:00</td>\n",
       "      <td>2016-04-26 10:02:00</td>\n",
       "      <td>4/26/16</td>\n",
       "      <td>9:33 AM</td>\n",
       "      <td>10:02 AM</td>\n",
       "      <td>listening to 80's pop, going through work email</td>\n",
       "      <td>work</td>\n",
       "      <td>Calm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-04-26 10:02:00</td>\n",
       "      <td>2016-04-26 10:25:00</td>\n",
       "      <td>4/26/16</td>\n",
       "      <td>10:02 AM</td>\n",
       "      <td>10:25 AM</td>\n",
       "      <td>meeting with student</td>\n",
       "      <td>work</td>\n",
       "      <td>Calm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-04-26 10:25:00</td>\n",
       "      <td>2016-04-26 10:35:00</td>\n",
       "      <td>4/26/16</td>\n",
       "      <td>10:25 AM</td>\n",
       "      <td>10:35 AM</td>\n",
       "      <td>meeting with mick</td>\n",
       "      <td>work</td>\n",
       "      <td>Calm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-04-26 10:35:00</td>\n",
       "      <td>2016-04-26 10:45:00</td>\n",
       "      <td>4/26/16</td>\n",
       "      <td>10:35 AM</td>\n",
       "      <td>10:45 AM</td>\n",
       "      <td>meeting with student</td>\n",
       "      <td>school</td>\n",
       "      <td>Calm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            starttime             endtime     date     start       end  \\\n",
       "0 2016-04-26 09:28:00 2016-04-26 09:33:00  4/26/16   9:28 AM   9:33 AM   \n",
       "1 2016-04-26 09:33:00 2016-04-26 10:02:00  4/26/16   9:33 AM  10:02 AM   \n",
       "2 2016-04-26 10:02:00 2016-04-26 10:25:00  4/26/16  10:02 AM  10:25 AM   \n",
       "3 2016-04-26 10:25:00 2016-04-26 10:35:00  4/26/16  10:25 AM  10:35 AM   \n",
       "4 2016-04-26 10:35:00 2016-04-26 10:45:00  4/26/16  10:35 AM  10:45 AM   \n",
       "\n",
       "                                            activity location generalemo  \\\n",
       "0  setting up basis, drinking coffee, listening t...     work       Calm   \n",
       "1    listening to 80's pop, going through work email     work       Calm   \n",
       "2                               meeting with student     work       Calm   \n",
       "3                                  meeting with mick     work       Calm   \n",
       "4                               meeting with student   school       Calm   \n",
       "\n",
       "   qualitative  excited    ...      ansa  boolexcited  boolhappy  boolcalm  \\\n",
       "0            0        1    ...     False         True       True      True   \n",
       "1            0        0    ...     False        False       True      True   \n",
       "2            0        0    ...     False        False      False      True   \n",
       "3            0        0    ...     False        False      False      True   \n",
       "4            0        0    ...     False        False      False      True   \n",
       "\n",
       "   boolanxious  boolsad  boolangry  booltired boolhungry boolbored  \n",
       "0        False    False      False       True      False      True  \n",
       "1        False    False      False       True      False     False  \n",
       "2        False    False      False       True      False     False  \n",
       "3        False    False      False       True      False     False  \n",
       "4        False    False      False       True      False     False  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "journal['boolexcited'] =  journal['excited'] > 0\n",
    "journal['boolhappy'] =  journal['happy'] > 0\n",
    "journal['boolcalm'] =  journal['calm'] > 0\n",
    "journal['boolanxious'] =  journal['anxious'] > 0\n",
    "journal['boolsad'] =  journal['sad'] > 0\n",
    "journal['boolangry'] =  journal['angry'] > 0\n",
    "journal['booltired'] =  journal['tired'] > 0\n",
    "journal['boolhungry'] =  journal['hungry'] > 0\n",
    "journal['boolbored'] =  journal['bored'] > 0\n",
    "journal['exhaca'] =  journal['exhaca'] > 0\n",
    "journal['ansaan'] =  journal['ansaan'] > 0\n",
    "\n",
    "journal['exha'] =  journal['exha'] > 0\n",
    "journal['haca'] =  journal['haca'] > 0\n",
    "journal['anan'] =  journal['anan'] > 0\n",
    "journal['ansa'] =  journal['anan'] > 0\n",
    "\n",
    "    \n",
    "boolexcited = journal.iloc[:, 18].values.reshape(journal.shape[0], 1)\n",
    "boolhappy = journal.iloc[:, 19].values.reshape(journal.shape[0], 1)\n",
    "boolcalm = journal.iloc[:, 20].values.reshape(journal.shape[0], 1)\n",
    "boolanxious = journal.iloc[:, 21].values.reshape(journal.shape[0], 1)\n",
    "boolsad = journal.iloc[:, 22].values.reshape(journal.shape[0], 1)\n",
    "boolangry = journal.iloc[:, 23].values.reshape(journal.shape[0], 1)\n",
    "booltired = journal.iloc[:, 24].values.reshape(journal.shape[0], 1)\n",
    "boolhungry = journal.iloc[:, 25].values.reshape(journal.shape[0], 1)\n",
    "boolbored = journal.iloc[:, 26].values.reshape(journal.shape[0], 1)\n",
    "exhaca = journal.iloc[:, 27].values.reshape(journal.shape[0], 1)\n",
    "ansaan = journal.iloc[:, 28].values.reshape(journal.shape[0], 1)\n",
    "exha = journal.iloc[:, 29].values.reshape(journal.shape[0], 1)\n",
    "haca = journal.iloc[:, 30].values.reshape(journal.shape[0], 1)\n",
    "anan = journal.iloc[:, 31].values.reshape(journal.shape[0], 1)\n",
    "ansa = journal.iloc[:, 32].values.reshape(journal.shape[0], 1)\n",
    "\n",
    "journal.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for i in range(0, sarahJournal.shape[0]):\n",
    "#     sarahJournal['ex'] = (0< sarahJournal.iloc[i, 18].astype(int))\n",
    "#     sarahJournal['ha'] = sarahJournal.iloc[i, 19]== True\n",
    "#     sarahJournal['ca'] = sarahJournal.iloc[i, 20]== True\n",
    "#     sarahJournal['ys'] = sarahJournal['ex'].astype(int) + sarahJournal['ha'].astype(int) + sarahJournal['ca'].astype(int)\n",
    "\n",
    "# print(sarahJournal['ex'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def makeEmoIndicators(newvar, journalData, journal_emo1_loc, journal_emo2_loc, journal_emo3_loc):\n",
    "  \n",
    "#     journalData[newvar] = False\n",
    "    \n",
    "#     for i in range(0, journalData.shape[0]):\n",
    "#         journalData['emo1'] = (journalData.iloc[i, journal_emo1_loc]) == True)\n",
    "#         journalData['emo2'] = (journalData.iloc[i, journal_emo2_loc] == True)\n",
    "#         journalData['emo3'] = (journalData.iloc[i, journal_emo3_loc] == True)\n",
    "#         journalData['ysum'] = journalData['emo1'].astype(int) + journalData['emo2'].astype(int) + journalData['emo3'].astype(int)\n",
    "# #         print(journalData['emo1'].astype(int) + journalData['emo2'].astype(int) + journalData['emo3'].astype(int))\n",
    "#         journalData.loc[journalData['ysum']!=0, newvar] = True\n",
    "        \n",
    "#     print(journalData['emo1'].values)\n",
    "#     journalData = journalData.drop(['emo1', 'emo2', 'emo3', 'ysum'], axis=1)\n",
    "#     return journalData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sarahJournal.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# testData= makeEmoIndicators('exhaca', sarahJournal, 18, 19, 20)\n",
    "# # print(testData.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sarahJournal.boolexhapcal.convert_objects(convert_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function that takes any journal or activity data and creates indicators for activities or emotions\n",
    "\n",
    "def makeIndicators(newvar, metricData, journalData, journal_startdatetime_loc, journal_enddatetime_loc, journal_activity_loc):\n",
    "    '''\n",
    "    Create boolean indicator variable for activities or emotions\n",
    "    newvar, string for name of new indicator variable\n",
    "    activity, string that matches the name of the activity or emotion in the journalData data frame\n",
    "    bioData, data frame of input biometric data\n",
    "    journalData, data frame of input journal or activity data\n",
    "    journal_startdatetime_loc, int of position of the start datetime in journalData\n",
    "    journal_enddatetime_loc, int of position of the end datetime in journalData\n",
    "    journal_activity_loc, int of position of the activity or emotion in journalData\n",
    "    '''\n",
    "\n",
    "    metricData[newvar] = False\n",
    "\n",
    "    for i in range(0, journalData.shape[0]):\n",
    "        metricData['xlt'] = (metricData['timestamp'] >= pd.to_datetime(journalData.iloc[i, journal_startdatetime_loc]))\n",
    "        metricData['xgt'] = (metricData['timestamp'] <= pd.to_datetime(journalData.iloc[i, journal_enddatetime_loc]))\n",
    "#         metricData['xw'] = (journalData.iloc[i, journal_activity_loc])\n",
    "        metricData['xw'] = (journalData.iloc[i, journal_activity_loc] == True)\n",
    "        metricData['xsum'] = metricData['xlt'].astype(int) + metricData['xgt'].astype(int) + metricData['xw'].astype(int)\n",
    "        metricData.loc[metricData['xsum']==3, newvar] = True\n",
    "    \n",
    "    metricData = metricData.drop(['xlt', 'xgt', 'xw', 'xsum'], axis=1)\n",
    "    return metricData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# indicator for walking\n",
    "totalData = makeIndicators('excitement', metrics, journal, 0, 1, 18)\n",
    "totalData = makeIndicators('happy', metrics, journal, 0, 1, 19)\n",
    "totalData = makeIndicators('calm', metrics, journal, 0, 1, 20)\n",
    "totalData = makeIndicators('anxious', metrics, journal, 0, 1, 21)\n",
    "totalData = makeIndicators('sad', metrics, journal, 0, 1, 22)\n",
    "totalData = makeIndicators('angry', metrics, journal, 0, 1, 23)\n",
    "totalData = makeIndicators('hungry', metrics, journal, 0, 1, 24)\n",
    "totalData = makeIndicators('tired', metrics, journal, 0, 1, 25)\n",
    "totalData = makeIndicators('bored', metrics, journal, 0, 1, 26)\n",
    "\n",
    "totalData = makeIndicators('exhaca', metrics, journal, 0, 1, 27)\n",
    "totalData = makeIndicators('ansaan', metrics, journal, 0, 1, 28)\n",
    "\n",
    "totalData = makeIndicators('exha', metrics, journal, 0, 1, 29)\n",
    "totalData = makeIndicators('haca', metrics, journal, 0, 1, 30)\n",
    "totalData = makeIndicators('anan', metrics, journal, 0, 1, 31)\n",
    "totalData = makeIndicators('ansa', metrics, journal, 0, 1, 32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          heartrate         steps      calories           gsr      skintemp  \\\n",
      "count  10080.000000  10080.000000  10080.000000  10080.000000  10080.000000   \n",
      "mean      65.284623      3.466567      1.658363      0.001082     70.396171   \n",
      "std       35.596657     16.000542      1.467958      0.018148     35.013143   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%       57.000000      0.000000      1.100000      0.000055     82.400000   \n",
      "50%       76.000000      0.000000      1.300000      0.000060     86.900000   \n",
      "75%       88.000000      0.000000      1.900000      0.000073     88.700000   \n",
      "max      198.000000    124.000000     17.200000      0.719000     97.700000   \n",
      "\n",
      "            airtemp excitement     happy       calm   anxious     ...       \\\n",
      "count  10080.000000      10080     10080      10080     10080     ...        \n",
      "mean      67.822421   0.509127   0.48006  0.0570437  0.509127     ...        \n",
      "std       33.805046   0.499941  0.499627   0.231938  0.499941     ...        \n",
      "min        0.000000      False     False      False     False     ...        \n",
      "25%       78.800000          0         0          0         0     ...        \n",
      "50%       83.300000          1         0          0         1     ...        \n",
      "75%       86.000000          1         1          0         1     ...        \n",
      "max      105.800000       True      True       True      True     ...        \n",
      "\n",
      "          angry       hungry      tired     bored    exhaca     ansaan  \\\n",
      "count     10080        10080      10080     10080     10080      10080   \n",
      "mean    0.48006  0.000595238  0.0570437  0.500198  0.338294  0.0662698   \n",
      "std    0.499627    0.0243914   0.231938  0.500025  0.473152   0.248766   \n",
      "min       False        False      False     False     False      False   \n",
      "25%           0            0          0         0         0          0   \n",
      "50%           0            0          0         1         0          0   \n",
      "75%           1            0          0         1         1          0   \n",
      "max        True         True       True      True      True       True   \n",
      "\n",
      "           exha       haca        anan         ansa  \n",
      "count     10080      10080       10080        10080  \n",
      "mean    0.25873  0.0470238  0.00119048  0.000595238  \n",
      "std    0.437959     0.2117   0.0344844    0.0243914  \n",
      "min       False      False       False        False  \n",
      "25%           0          0           0            0  \n",
      "50%           0          0           0            0  \n",
      "75%           1          0           0            0  \n",
      "max        True       True        True         True  \n",
      "\n",
      "[8 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "print(totalData.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            timestamp  heartrate  steps  calories  gsr  skintemp  airtemp  \\\n",
      "0 2016-04-26 00:00:00          0      0         0    0         0        0   \n",
      "1 2016-04-26 00:01:00          0      0         0    0         0        0   \n",
      "2 2016-04-26 00:02:00          0      0         0    0         0        0   \n",
      "3 2016-04-26 00:03:00          0      0         0    0         0        0   \n",
      "4 2016-04-26 00:04:00          0      0         0    0         0        0   \n",
      "\n",
      "  excitement  happy   calm  ...    angry hungry  tired  bored exhaca ansaan  \\\n",
      "0      False  False  False  ...    False  False  False  False  False  False   \n",
      "1      False  False  False  ...    False  False  False  False  False  False   \n",
      "2      False  False  False  ...    False  False  False  False  False  False   \n",
      "3      False  False  False  ...    False  False  False  False  False  False   \n",
      "4      False  False  False  ...    False  False  False  False  False  False   \n",
      "\n",
      "    exha   haca   anan   ansa  \n",
      "0  False  False  False  False  \n",
      "1  False  False  False  False  \n",
      "2  False  False  False  False  \n",
      "3  False  False  False  False  \n",
      "4  False  False  False  False  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "print(totalData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "totalData.to_csv('sarahTotal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>steps</th>\n",
       "      <th>calories</th>\n",
       "      <th>gsr</th>\n",
       "      <th>skintemp</th>\n",
       "      <th>airtemp</th>\n",
       "      <th>excitement</th>\n",
       "      <th>happy</th>\n",
       "      <th>calm</th>\n",
       "      <th>...</th>\n",
       "      <th>angry</th>\n",
       "      <th>hungry</th>\n",
       "      <th>tired</th>\n",
       "      <th>bored</th>\n",
       "      <th>exhaca</th>\n",
       "      <th>ansaan</th>\n",
       "      <th>exha</th>\n",
       "      <th>haca</th>\n",
       "      <th>anan</th>\n",
       "      <th>ansa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-26 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-04-26 00:01:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-04-26 00:02:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-04-26 00:03:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-04-26 00:04:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  heartrate  steps  calories  gsr  skintemp  airtemp  \\\n",
       "0 2016-04-26 00:00:00          0      0         0    0         0        0   \n",
       "1 2016-04-26 00:01:00          0      0         0    0         0        0   \n",
       "2 2016-04-26 00:02:00          0      0         0    0         0        0   \n",
       "3 2016-04-26 00:03:00          0      0         0    0         0        0   \n",
       "4 2016-04-26 00:04:00          0      0         0    0         0        0   \n",
       "\n",
       "  excitement  happy   calm  ...    angry hungry  tired  bored exhaca ansaan  \\\n",
       "0      False  False  False  ...    False  False  False  False  False  False   \n",
       "1      False  False  False  ...    False  False  False  False  False  False   \n",
       "2      False  False  False  ...    False  False  False  False  False  False   \n",
       "3      False  False  False  ...    False  False  False  False  False  False   \n",
       "4      False  False  False  ...    False  False  False  False  False  False   \n",
       "\n",
       "    exha   haca   anan   ansa  \n",
       "0  False  False  False  False  \n",
       "1  False  False  False  False  \n",
       "2  False  False  False  False  \n",
       "3  False  False  False  False  \n",
       "4  False  False  False  False  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalData.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10080, 26)\n",
      "            timestamp  heartrate  steps  calories  gsr  skintemp  airtemp  \\\n",
      "0 2016-04-26 00:00:00          0      0         0    0         0        0   \n",
      "1 2016-04-26 00:01:00          0      0         0    0         0        0   \n",
      "2 2016-04-26 00:02:00          0      0         0    0         0        0   \n",
      "3 2016-04-26 00:03:00          0      0         0    0         0        0   \n",
      "4 2016-04-26 00:04:00          0      0         0    0         0        0   \n",
      "\n",
      "  excitement  happy   calm ... exhaca ansaan   exha   haca   anan   ansa  \\\n",
      "0      False  False  False ...  False  False  False  False  False  False   \n",
      "1      False  False  False ...  False  False  False  False  False  False   \n",
      "2      False  False  False ...  False  False  False  False  False  False   \n",
      "3      False  False  False ...  False  False  False  False  False  False   \n",
      "4      False  False  False ...  False  False  False  False  False  False   \n",
      "\n",
      "  weekday month hour min  \n",
      "0       1     4    0   0  \n",
      "1       1     4    0   1  \n",
      "2       1     4    0   2  \n",
      "3       1     4    0   3  \n",
      "4       1     4    0   4  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# find day of week (0-6, Mon-Sun)\n",
    "totalData['weekday'] = totalData['timestamp'].dt.weekday\n",
    "totalData['month'] = totalData['timestamp'].dt.month\n",
    "totalData['hour'] = totalData['timestamp'].dt.hour\n",
    "totalData['min'] = totalData['timestamp'].dt.minute\n",
    "\n",
    "\n",
    "print(totalData.shape)\n",
    "print(totalData.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "heartrate = totalData.iloc[:, 1].values.reshape(totalData.shape[0], 1)\n",
    "steps = totalData.iloc[:, 2].values.reshape(totalData.shape[0], 1)\n",
    "calories = totalData.iloc[:, 3].values.reshape(totalData.shape[0], 1)\n",
    "gsr = totalData.iloc[:, 4].values.reshape(totalData.shape[0], 1)\n",
    "skintemp = totalData.iloc[:, 5].values.reshape(totalData.shape[0], 1)\n",
    "airtemp = totalData.iloc[:, 6].values.reshape(totalData.shape[0], 1)\n",
    "# activity = totalData.iloc[:, 17].values.reshape(totalData.shape[0], 1)\n",
    "# exercise = totalData.iloc[:, 17].values.reshape(totalData.shape[0], 1)\n",
    "# thesis = totalData.iloc[:, 18].values.reshape(totalData.shape[0], 1)\n",
    "# sally = totalData.iloc[:, 19].values.reshape(totalData.shape[0], 1)\n",
    "# barb = totalData.iloc[:, 20].values.reshape(totalData.shape[0], 1)\n",
    "# sol = totalData.iloc[:, 21].values.reshape(totalData.shape[0], 1)\n",
    "# arash = totalData.iloc[:, 22].values.reshape(totalData.shape[0], 1)\n",
    "# work = totalData.iloc[:, 23].values.reshape(totalData.shape[0], 1)\n",
    "# home = totalData.iloc[:, 24].values.reshape(totalData.shape[0], 1)\n",
    "# DayOfWeek = totalData.iloc[:, 25].values.reshape(totalData.shape[0], 1)\n",
    "# Month = totalData.iloc[:, 26].values.reshape(totalData.shape[0], 1)\n",
    "weekday = totalData.iloc[:, 7].values.reshape(totalData.shape[0], 1)\n",
    "# month = totalData.iloc[:, 29].values.reshape(totalData.shape[0], 1)\n",
    "hour = totalData.iloc[:, 8].values.reshape(totalData.shape[0], 1)\n",
    "curmin = totalData.iloc[:, 9].values.reshape(totalData.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10080, 9)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate to numpy dataset\n",
    "X = np.concatenate((\n",
    "        heartrate, \n",
    "        steps, \n",
    "        calories, \n",
    "        gsr, \n",
    "        skintemp, \n",
    "        airtemp, \n",
    "#         exercise, \n",
    "#         thesis, \n",
    "#         sally, \n",
    "#         barb, \n",
    "#         sol, \n",
    "#         arash, \n",
    "#         work, \n",
    "#         home, \n",
    "        weekday, \n",
    "        hour, \n",
    "        curmin\n",
    "    ), axis=1)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positive ( Excited, Happy, Calm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10080,)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define y\n",
    "\n",
    "\n",
    "y = totalData.exhaca.values\n",
    "\n",
    "# y = totalData.excitement.values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# report on training and test sets\n",
    "global SVMerror, SVMacc, SVMtp, SVMtn, LRerror, LRacc, LRtp, LRtn, NBerror, NBacc, NBtp, NBtn, Perror, Pacc, Ptp, Ptn\n",
    "\n",
    "\n",
    "\n",
    "def print_results(model):\n",
    "    #print('Error rate on training set: ')\n",
    "    erTRAIN = ((y_train != y_pred).sum() / X_train.shape[0])\n",
    "    #print('Accuracy rate on training set: ')\n",
    "    AccTRAIN = (1 - (y_train != y_pred).sum() / X_train.shape[0])\n",
    "    #print('True positive rate on training tet:')\n",
    "    TruPosTRAIN = ((y_train==True) & (y_pred==True)).sum() / y_train.sum()\n",
    "    #TruNegTEST = (((y_train==False) & (y_pred_train==False)).sum() / (y_train.shape[0] - y_train.sum()))\n",
    "    #print('**************')\n",
    "    #('Error rate on test set: ')\n",
    "    erTEST = ((y_test != y_pred_test).sum() / X_test.shape[0])\n",
    "    #print('Accuracy rate on test set: ')\n",
    "    AccTEST = (1 - (y_test != y_pred_test).sum() / X_test.shape[0])\n",
    "    #print('True positive rate on test set')\n",
    "    TruPosTEST = (((y_test==True) & (y_pred_test==True)).sum() / y_test.sum())\n",
    "    #print('True negative rate on test set')\n",
    "    TruNegTEST = (((y_test==False) & (y_pred_test==False)).sum() / (y_test.shape[0] - y_test.sum()))\n",
    "    data_rows = [('Error Rate', erTRAIN, erTEST),\n",
    "                 ('Accuracy Rate', AccTRAIN, AccTEST),\n",
    "                 ('True Positives', TruPosTRAIN, TruPosTEST),\n",
    "                 ('True Negatives', '--', TruNegTEST)]\n",
    "    t = Table(rows=data_rows, names=(model, 'Training Set', 'Test Set'), meta={'name': model + ': Training and Test Set Results'})\n",
    "    print(t)\n",
    "    if model == 'SVM':\n",
    "        SVMerror = erTEST\n",
    "        SVMacc = AccTEST\n",
    "        SVMtp = TruPosTEST\n",
    "        SVMtn = TruNegTEST\n",
    "        return(SVMerror, SVMacc, SVMtp, SVMtn)\n",
    "    elif model == 'Logistic Regression':\n",
    "        LRerror = erTEST\n",
    "        LRacc = AccTEST\n",
    "        LRtp = TruPosTEST\n",
    "        LRtn = TruNegTEST\n",
    "        return(LRerror, LRacc, LRtp, LRtn)\n",
    "    elif model == 'Naive Bayes':\n",
    "        NBerror = erTEST\n",
    "        NBacc = AccTEST\n",
    "        NBtp = TruPosTEST\n",
    "        NBtn = TruNegTEST\n",
    "        return(NBerror, NBacc, NBtp, NBtn)\n",
    "    elif model == 'Perceptron':\n",
    "        Perror = erTEST\n",
    "        Pacc = AccTEST\n",
    "        Ptp = TruPosTEST\n",
    "        Ptn = TruNegTEST\n",
    "        return(Perror, Pacc, Ptp, Ptn)\n",
    "    print('done')\n",
    "      \n",
    "    #t.show_in_browser(jsviewer=True) \n",
    "    \n",
    "    \n",
    "def all_models_table():\n",
    "    all_rows = [('SVM', SVMerror, SVMacc, SVMtp, SVMtn),\n",
    "            ('Logistic Regression', LRerror, LRacc, LRtp, LRtn),\n",
    "            ('Naive Bayes', NBerror, NBacc, NBtp, NBtn),\n",
    "            ('Perceptron', Perror, Pacc, Ptp, Ptn)]\n",
    "    tt = Table(rows=all_rows, names=('', 'Error Rate', 'Accuracy', 'True +', 'True -'), meta={'3/15/2016'})\n",
    "    print(tt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive ( Excited, Happy, Calm) Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SVM        Training Set     Test Set   \n",
      "-------------- -------------- --------------\n",
      "    Error Rate 0.112103174603 0.104828042328\n",
      " Accuracy Rate 0.887896825397 0.895171957672\n",
      "True Positives 0.938390611903    0.935546875\n",
      "True Negatives             --         0.8745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.10482804232804233, 0.89517195767195767, 0.935546875, 0.87450000000000006)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: SVM, linear\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression  Training Set     Test Set   \n",
      "------------------- -------------- --------------\n",
      "         Error Rate  0.21556122449 0.216931216931\n",
      "      Accuracy Rate  0.78443877551 0.783068783069\n",
      "     True Positives 0.370913663034    0.361328125\n",
      "     True Negatives             --          0.999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.21693121693121692, 0.78306878306878303, 0.361328125, 0.999)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: logistic regression\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Naive Bayes    Training Set     Test Set   \n",
      "-------------- -------------- --------------\n",
      "    Error Rate 0.157879818594 0.148148148148\n",
      " Accuracy Rate 0.842120181406 0.851851851852\n",
      "True Positives 0.893964794635     0.91015625\n",
      "True Negatives             --          0.822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.14814814814814814, 0.85185185185185186, 0.91015625, 0.82199999999999995)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Perceptron    Training Set     Test Set   \n",
      "-------------- -------------- --------------\n",
      "    Error Rate  0.11862244898 0.114417989418\n",
      " Accuracy Rate  0.88137755102 0.885582010582\n",
      "True Positives 0.952640402347      0.9453125\n",
      "True Negatives             --          0.855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.11441798941798942, 0.88558201058201058, 0.9453125, 0.85499999999999998)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='perceptron')\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Perceptron')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negative ( Anxious, Sad, Angry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10080,)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define y\n",
    "y = totalData.ansaan.values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative ( Anxious, Sad, Angry) Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SVM         Training Set      Test Set   \n",
      "-------------- --------------- ---------------\n",
      "    Error Rate 0.0666099773243 0.0658068783069\n",
      " Accuracy Rate  0.933390022676  0.934193121693\n",
      "True Positives             0.0             0.0\n",
      "True Negatives              --  0.999646142958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.065806878306878314, 0.93419312169312163, 0.0, 0.99964614295824483)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: SVM, linear\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression   Training Set      Test Set   \n",
      "------------------- --------------- ---------------\n",
      "         Error Rate 0.0666099773243 0.0658068783069\n",
      "      Accuracy Rate  0.933390022676  0.934193121693\n",
      "     True Positives             0.0             0.0\n",
      "     True Negatives              --  0.999646142958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.065806878306878314, 0.93419312169312163, 0.0, 0.99964614295824483)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: logistic regression\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Naive Bayes     Training Set      Test Set   \n",
      "-------------- --------------- ---------------\n",
      "    Error Rate 0.0634920634921 0.0658068783069\n",
      " Accuracy Rate  0.936507936508  0.934193121693\n",
      "True Positives  0.172340425532  0.161616161616\n",
      "True Negatives              --  0.988322717622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.065806878306878314,\n",
       " 0.93419312169312163,\n",
       " 0.16161616161616163,\n",
       " 0.98832271762208068)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Perceptron     Training Set      Test Set   \n",
      "-------------- --------------- ---------------\n",
      "    Error Rate 0.0666099773243 0.0654761904762\n",
      " Accuracy Rate  0.933390022676  0.934523809524\n",
      "True Positives             0.0             0.0\n",
      "True Negatives              --             1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.065476190476190479, 0.93452380952380953, 0.0, 1.0)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='perceptron')\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Perceptron')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Happy/Calm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10080,)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define y\n",
    "y = totalData.haca.values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Happy/Calm  Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SVM         Training Set      Test Set   \n",
      "-------------- --------------- ---------------\n",
      "    Error Rate 0.0493197278912 0.0416666666667\n",
      " Accuracy Rate  0.950680272109  0.958333333333\n",
      "True Positives             0.0             0.0\n",
      "True Negatives              --             1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.041666666666666664, 0.95833333333333337, 0.0, 1.0)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: SVM, linear\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression   Training Set      Test Set   \n",
      "------------------- --------------- ---------------\n",
      "         Error Rate 0.0493197278912 0.0416666666667\n",
      "      Accuracy Rate  0.950680272109  0.958333333333\n",
      "     True Positives             0.0             0.0\n",
      "     True Negatives              --             1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.041666666666666664, 0.95833333333333337, 0.0, 1.0)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: logistic regression\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Naive Bayes     Training Set      Test Set   \n",
      "-------------- --------------- ---------------\n",
      "    Error Rate 0.0493197278912 0.0416666666667\n",
      " Accuracy Rate  0.950680272109  0.958333333333\n",
      "True Positives             0.0             0.0\n",
      "True Negatives              --             1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.041666666666666664, 0.95833333333333337, 0.0, 1.0)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Perceptron     Training Set     Test Set   \n",
      "-------------- --------------- --------------\n",
      "    Error Rate 0.0497448979592 0.042328042328\n",
      " Accuracy Rate  0.950255102041 0.957671957672\n",
      "True Positives             0.0            0.0\n",
      "True Negatives              -- 0.999309868875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.042328042328042326, 0.95767195767195767, 0.0, 0.99930986887508622)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='perceptron')\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Perceptron')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anxious/Angry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10080,)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define y\n",
    "y = totalData.anan.values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anxious/Angry Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SVM         Training Set        Test Set    \n",
      "-------------- ---------------- -----------------\n",
      "    Error Rate 0.00127551020408 0.000992063492063\n",
      " Accuracy Rate   0.998724489796    0.999007936508\n",
      "True Positives              0.0               0.0\n",
      "True Negatives               --               1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.00099206349206349201, 0.99900793650793651, 0.0, 1.0)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: SVM, linear\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression   Training Set        Test Set    \n",
      "------------------- ---------------- -----------------\n",
      "         Error Rate 0.00127551020408 0.000992063492063\n",
      "      Accuracy Rate   0.998724489796    0.999007936508\n",
      "     True Positives              0.0               0.0\n",
      "     True Negatives               --               1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.00099206349206349201, 0.99900793650793651, 0.0, 1.0)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: logistic regression\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Naive Bayes     Training Set       Test Set    \n",
      "-------------- ---------------- ----------------\n",
      "    Error Rate 0.00198412698413 0.00198412698413\n",
      " Accuracy Rate   0.998015873016   0.998015873016\n",
      "True Positives              0.0              0.0\n",
      "True Negatives               --   0.999006951341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.001984126984126984, 0.99801587301587302, 0.0, 0.99900695134061568)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Perceptron     Training Set        Test Set    \n",
      "-------------- ---------------- -----------------\n",
      "    Error Rate 0.00127551020408 0.000992063492063\n",
      " Accuracy Rate   0.998724489796    0.999007936508\n",
      "True Positives              0.0               0.0\n",
      "True Negatives               --               1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.00099206349206349201, 0.99900793650793651, 0.0, 1.0)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='perceptron')\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Perceptron')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excited/Happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10080,)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define y\n",
    "y = totalData.exha.values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excited/Happy Model Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SVM         Training Set     Test Set   \n",
      "-------------- --------------- --------------\n",
      "    Error Rate  0.253259637188 0.243386243386\n",
      " Accuracy Rate  0.746740362812 0.756613756614\n",
      "True Positives 0.0315217391304     0.04296875\n",
      "True Negatives              -- 0.999556737589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.24338624338624337, 0.75661375661375663, 0.04296875, 0.99955673758865249)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: SVM, linear\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression  Training Set     Test Set   \n",
      "------------------- -------------- --------------\n",
      "         Error Rate 0.163548752834 0.171626984127\n",
      "      Accuracy Rate 0.836451247166 0.828373015873\n",
      "     True Positives 0.970108695652     0.98046875\n",
      "     True Negatives             -- 0.776595744681\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.17162698412698413, 0.82837301587301582, 0.98046875, 0.77659574468085102)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: logistic regression\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Naive Bayes    Training Set     Test Set   \n",
      "-------------- -------------- --------------\n",
      "    Error Rate 0.106009070295  0.10582010582\n",
      " Accuracy Rate 0.893990929705  0.89417989418\n",
      "True Positives 0.724456521739     0.72265625\n",
      "True Negatives             -- 0.952570921986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.10582010582010581, 0.89417989417989419, 0.72265625, 0.95257092198581561)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Perceptron    Training Set     Test Set   \n",
      "-------------- -------------- --------------\n",
      "    Error Rate 0.111394557823 0.112764550265\n",
      " Accuracy Rate 0.888605442177 0.887235449735\n",
      "True Positives 0.770652173913 0.776041666667\n",
      "True Negatives             -- 0.925088652482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.11276455026455026,\n",
       " 0.88723544973544977,\n",
       " 0.77604166666666663,\n",
       " 0.92508865248226946)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='perceptron')\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Perceptron')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anxious/Sad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10080,)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define y\n",
    "y = totalData.ansa.values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anxious/Sad Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SVM          Training Set        Test Set    \n",
      "-------------- ----------------- -----------------\n",
      "    Error Rate 0.000566893424036 0.000330687830688\n",
      " Accuracy Rate    0.999433106576    0.999669312169\n",
      "True Positives               0.4               0.0\n",
      "True Negatives                --               1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.00033068783068783067, 0.99966931216931221, 0.0, 1.0)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: SVM, linear\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression    Training Set        Test Set    \n",
      "------------------- ----------------- -----------------\n",
      "         Error Rate 0.000566893424036 0.000330687830688\n",
      "      Accuracy Rate    0.999433106576    0.999669312169\n",
      "     True Positives               0.4               0.0\n",
      "     True Negatives                --               1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.00033068783068783067, 0.99966931216931221, 0.0, 1.0)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: logistic regression\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Naive Bayes     Training Set      Test Set   \n",
      "-------------- --------------- ---------------\n",
      "    Error Rate 0.0337301587302 0.0337301587302\n",
      " Accuracy Rate   0.96626984127   0.96626984127\n",
      "True Positives             1.0             1.0\n",
      "True Negatives              --  0.966258683427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.033730158730158728, 0.96626984126984128, 1.0, 0.96625868342705923)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Perceptron      Training Set        Test Set    \n",
      "-------------- ----------------- -----------------\n",
      "    Error Rate 0.000566893424036 0.000330687830688\n",
      " Accuracy Rate    0.999433106576    0.999669312169\n",
      "True Positives               0.4               0.0\n",
      "True Negatives                --               1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.00033068783068783067, 0.99966931216931221, 0.0, 1.0)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='perceptron')\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Perceptron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
