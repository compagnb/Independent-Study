{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np #import numpy library\n",
    "import pandas as pd #import pandas library\n",
    "import matplotlib.pyplot as plt #import matplot library\n",
    "%matplotlib inline\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import nltk.classify.util\n",
    "from astropy.table import Table, Column\n",
    "\n",
    "import string\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " def loadMetricData(user, directory):\n",
    "    path =  user + \"/\" + directory + \"/\"\n",
    "#     print(path)\n",
    "    all_files = glob.glob(os.path.join(path, \"*.csv\")) \n",
    "#     print(all_files)\n",
    "    data = pd.DataFrame()\n",
    "    list_ = []\n",
    "    for file_ in all_files:\n",
    "        data = pd.read_csv(file_,index_col=None, header=0)\n",
    "        list_.append(data)\n",
    "        data = pd.concat(list_)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # clean times function\n",
    "def cleanTime(df, col):\n",
    "    df.col = pd.to_datetime(df.col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # replace NAN's\n",
    "# def rmNAN(df, col):\n",
    "#     df.col = df.col.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>steps</th>\n",
       "      <th>calories</th>\n",
       "      <th>gsr</th>\n",
       "      <th>skintemp</th>\n",
       "      <th>airtemp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>2016-05-31 23:55:00</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>90.5</td>\n",
       "      <td>88.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>2016-05-31 23:56:00</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>90.5</td>\n",
       "      <td>88.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>2016-05-31 23:57:00</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>91.4</td>\n",
       "      <td>89.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>2016-05-31 23:58:00</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>91.4</td>\n",
       "      <td>89.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>2016-05-31 23:59:00</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>91.4</td>\n",
       "      <td>90.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp  heartrate  steps  calories       gsr  skintemp  \\\n",
       "1435  2016-05-31 23:55:00         74      0       0.9  0.000058      90.5   \n",
       "1436  2016-05-31 23:56:00         74      0       0.9  0.000059      90.5   \n",
       "1437  2016-05-31 23:57:00         74      0       1.0  0.000059      91.4   \n",
       "1438  2016-05-31 23:58:00         74      0       0.9  0.000060      91.4   \n",
       "1439  2016-05-31 23:59:00         75      0       0.9  0.000060      91.4   \n",
       "\n",
       "      airtemp  \n",
       "1435     88.7  \n",
       "1436     88.7  \n",
       "1437     89.6  \n",
       "1438     89.6  \n",
       "1439     90.5  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sallyMetrics = loadMetricData('sallyKung', \"metrics\")\n",
    "sallyMetrics.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp     object\n",
       "heartrate    float64\n",
       "steps          int64\n",
       "calories     float64\n",
       "gsr          float64\n",
       "skintemp     float64\n",
       "airtemp      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sallyMetrics.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>steps</th>\n",
       "      <th>calories</th>\n",
       "      <th>gsr</th>\n",
       "      <th>skintemp</th>\n",
       "      <th>airtemp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-05-02 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-05-02 00:01:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-05-02 00:02:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-05-02 00:03:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-05-02 00:04:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  heartrate  steps  calories  gsr  skintemp  airtemp\n",
       "0 2016-05-02 00:00:00          0      4     1.709    0         0        0\n",
       "1 2016-05-02 00:01:00          0      4     1.709    0         0        0\n",
       "2 2016-05-02 00:02:00          0      4     1.709    0         0        0\n",
       "3 2016-05-02 00:03:00          0      4     1.709    0         0        0\n",
       "4 2016-05-02 00:04:00          0      4     1.709    0         0        0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean metric data\n",
    "\n",
    "sallyMetrics.timestamp = pd.to_datetime(sallyMetrics.timestamp)\n",
    "\n",
    "sallyMetrics.heartrate = sallyMetrics.heartrate.fillna(0)\n",
    "sallyMetrics.steps = sallyMetrics.steps.fillna(0)\n",
    "sallyMetrics.calories = sallyMetrics.calories.fillna(0)\n",
    "sallyMetrics.gsr = sallyMetrics.gsr.fillna(0)\n",
    "sallyMetrics.skintemp = sallyMetrics.skintemp.fillna(0)\n",
    "sallyMetrics.airtemp = sallyMetrics.airtemp.fillna(0)\n",
    "\n",
    "sallyMetrics.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start time</th>\n",
       "      <th>start time ISO</th>\n",
       "      <th>start time timezone</th>\n",
       "      <th>start time offset</th>\n",
       "      <th>end time</th>\n",
       "      <th>end time ISO</th>\n",
       "      <th>end time timezone</th>\n",
       "      <th>end time offset</th>\n",
       "      <th>type</th>\n",
       "      <th>actual seconds</th>\n",
       "      <th>steps</th>\n",
       "      <th>calories</th>\n",
       "      <th>minutes</th>\n",
       "      <th>heart rate avg</th>\n",
       "      <th>heart rate min</th>\n",
       "      <th>heart rate max</th>\n",
       "      <th>state</th>\n",
       "      <th>version</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-06-06 06:54:29</td>\n",
       "      <td>2016-06-06T06:54:29Z</td>\n",
       "      <td>Asia/Shanghai</td>\n",
       "      <td>480</td>\n",
       "      <td>2016-06-06 07:04:43</td>\n",
       "      <td>2016-06-06T07:04:43Z</td>\n",
       "      <td>Asia/Shanghai</td>\n",
       "      <td>480</td>\n",
       "      <td>walk</td>\n",
       "      <td>528</td>\n",
       "      <td>912</td>\n",
       "      <td>30.600000</td>\n",
       "      <td>10.233333</td>\n",
       "      <td>110.592804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>walk__2016-06-06T065429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-06-06 09:32:27</td>\n",
       "      <td>2016-06-06T09:32:27Z</td>\n",
       "      <td>Asia/Shanghai</td>\n",
       "      <td>480</td>\n",
       "      <td>2016-06-06 10:02:15</td>\n",
       "      <td>2016-06-06T10:02:15Z</td>\n",
       "      <td>Asia/Shanghai</td>\n",
       "      <td>480</td>\n",
       "      <td>walk</td>\n",
       "      <td>1251</td>\n",
       "      <td>2152</td>\n",
       "      <td>68.099998</td>\n",
       "      <td>29.800000</td>\n",
       "      <td>112.898483</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>walk__2016-06-06T093227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-06-06 12:30:14</td>\n",
       "      <td>2016-06-06T12:30:14Z</td>\n",
       "      <td>Asia/Shanghai</td>\n",
       "      <td>480</td>\n",
       "      <td>2016-06-06 12:38:08</td>\n",
       "      <td>2016-06-06T12:38:08Z</td>\n",
       "      <td>Asia/Shanghai</td>\n",
       "      <td>480</td>\n",
       "      <td>walk</td>\n",
       "      <td>278</td>\n",
       "      <td>453</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>96.730217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>walk__2016-06-06T123014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-06-06 12:58:30</td>\n",
       "      <td>2016-06-06T12:58:30Z</td>\n",
       "      <td>Asia/Shanghai</td>\n",
       "      <td>480</td>\n",
       "      <td>2016-06-06 13:05:33</td>\n",
       "      <td>2016-06-06T13:05:33Z</td>\n",
       "      <td>Asia/Shanghai</td>\n",
       "      <td>480</td>\n",
       "      <td>walk</td>\n",
       "      <td>348</td>\n",
       "      <td>621</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>7.050000</td>\n",
       "      <td>100.965515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>walk__2016-06-06T125830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-06-06 13:23:07</td>\n",
       "      <td>2016-06-06T13:23:07Z</td>\n",
       "      <td>Asia/Shanghai</td>\n",
       "      <td>480</td>\n",
       "      <td>2016-06-06 13:27:43</td>\n",
       "      <td>2016-06-06T13:27:43Z</td>\n",
       "      <td>Asia/Shanghai</td>\n",
       "      <td>480</td>\n",
       "      <td>walk</td>\n",
       "      <td>233</td>\n",
       "      <td>419</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>93.738197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>walk__2016-06-06T132307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            start time        start time ISO start time timezone  \\\n",
       "1  2016-06-06 06:54:29  2016-06-06T06:54:29Z       Asia/Shanghai   \n",
       "2  2016-06-06 09:32:27  2016-06-06T09:32:27Z       Asia/Shanghai   \n",
       "3  2016-06-06 12:30:14  2016-06-06T12:30:14Z       Asia/Shanghai   \n",
       "4  2016-06-06 12:58:30  2016-06-06T12:58:30Z       Asia/Shanghai   \n",
       "5  2016-06-06 13:23:07  2016-06-06T13:23:07Z       Asia/Shanghai   \n",
       "\n",
       "   start time offset             end time          end time ISO  \\\n",
       "1                480  2016-06-06 07:04:43  2016-06-06T07:04:43Z   \n",
       "2                480  2016-06-06 10:02:15  2016-06-06T10:02:15Z   \n",
       "3                480  2016-06-06 12:38:08  2016-06-06T12:38:08Z   \n",
       "4                480  2016-06-06 13:05:33  2016-06-06T13:05:33Z   \n",
       "5                480  2016-06-06 13:27:43  2016-06-06T13:27:43Z   \n",
       "\n",
       "  end time timezone  end time offset  type  actual seconds  steps   calories  \\\n",
       "1     Asia/Shanghai              480  walk             528    912  30.600000   \n",
       "2     Asia/Shanghai              480  walk            1251   2152  68.099998   \n",
       "3     Asia/Shanghai              480  walk             278    453   8.500000   \n",
       "4     Asia/Shanghai              480  walk             348    621  11.800000   \n",
       "5     Asia/Shanghai              480  walk             233    419   6.100000   \n",
       "\n",
       "     minutes  heart rate avg  heart rate min  heart rate max     state  \\\n",
       "1  10.233333      110.592804             NaN             NaN  complete   \n",
       "2  29.800000      112.898483             NaN             NaN  complete   \n",
       "3   7.900000       96.730217             NaN             NaN  complete   \n",
       "4   7.050000      100.965515             NaN             NaN  complete   \n",
       "5   4.600000       93.738197             NaN             NaN  complete   \n",
       "\n",
       "   version                       id  \n",
       "1        1  walk__2016-06-06T065429  \n",
       "2        1  walk__2016-06-06T093227  \n",
       "3        1  walk__2016-06-06T123014  \n",
       "4        1  walk__2016-06-06T125830  \n",
       "5        1  walk__2016-06-06T132307  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sallyActivities = loadMetricData('sallyKung', \"activities\")\n",
    "sallyActivities.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start time</th>\n",
       "      <th>start time ISO</th>\n",
       "      <th>start time timezone</th>\n",
       "      <th>start time offset</th>\n",
       "      <th>end time</th>\n",
       "      <th>end time ISO</th>\n",
       "      <th>end time timezone</th>\n",
       "      <th>end time offset</th>\n",
       "      <th>light mins</th>\n",
       "      <th>deep mins</th>\n",
       "      <th>...</th>\n",
       "      <th>toss turns</th>\n",
       "      <th>type</th>\n",
       "      <th>actual seconds</th>\n",
       "      <th>calories</th>\n",
       "      <th>heart rate avg</th>\n",
       "      <th>heart rate min</th>\n",
       "      <th>heart rate max</th>\n",
       "      <th>state</th>\n",
       "      <th>version</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-06-02 16:56:58</td>\n",
       "      <td>2016-06-02T16:56:58Z</td>\n",
       "      <td>Asia/Shanghai</td>\n",
       "      <td>480</td>\n",
       "      <td>2016-06-03 00:49:45</td>\n",
       "      <td>2016-06-03T00:49:45Z</td>\n",
       "      <td>Asia/Shanghai</td>\n",
       "      <td>480</td>\n",
       "      <td>252</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>sleep</td>\n",
       "      <td>28320</td>\n",
       "      <td>437.200012</td>\n",
       "      <td>59.062733</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>complete</td>\n",
       "      <td>2</td>\n",
       "      <td>sleep__2016-06-02T165658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-06-03 17:07:29</td>\n",
       "      <td>2016-06-03T17:07:29Z</td>\n",
       "      <td>Asia/Shanghai</td>\n",
       "      <td>480</td>\n",
       "      <td>2016-06-04 02:03:05</td>\n",
       "      <td>2016-06-04T02:03:05Z</td>\n",
       "      <td>Asia/Shanghai</td>\n",
       "      <td>480</td>\n",
       "      <td>326</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>sleep</td>\n",
       "      <td>32100</td>\n",
       "      <td>495.100006</td>\n",
       "      <td>67.824936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>complete</td>\n",
       "      <td>2</td>\n",
       "      <td>sleep__2016-06-03T170729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-06-04 18:36:17</td>\n",
       "      <td>2016-06-04T18:36:17Z</td>\n",
       "      <td>Asia/Shanghai</td>\n",
       "      <td>480</td>\n",
       "      <td>2016-06-05 03:51:17</td>\n",
       "      <td>2016-06-05T03:51:17Z</td>\n",
       "      <td>Asia/Shanghai</td>\n",
       "      <td>480</td>\n",
       "      <td>232</td>\n",
       "      <td>165</td>\n",
       "      <td>...</td>\n",
       "      <td>46</td>\n",
       "      <td>sleep</td>\n",
       "      <td>33300</td>\n",
       "      <td>513.400024</td>\n",
       "      <td>67.653275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>complete</td>\n",
       "      <td>2</td>\n",
       "      <td>sleep__2016-06-04T183617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-06-05 18:20:50</td>\n",
       "      <td>2016-06-05T18:20:50Z</td>\n",
       "      <td>Asia/Shanghai</td>\n",
       "      <td>480</td>\n",
       "      <td>2016-06-06 02:19:31</td>\n",
       "      <td>2016-06-06T02:19:31Z</td>\n",
       "      <td>Asia/Shanghai</td>\n",
       "      <td>480</td>\n",
       "      <td>277</td>\n",
       "      <td>94</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>sleep</td>\n",
       "      <td>28680</td>\n",
       "      <td>443.100006</td>\n",
       "      <td>61.587814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>complete</td>\n",
       "      <td>2</td>\n",
       "      <td>sleep__2016-06-05T182050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-06-06 02:51:35</td>\n",
       "      <td>2016-06-06T02:51:35Z</td>\n",
       "      <td>Asia/Shanghai</td>\n",
       "      <td>480</td>\n",
       "      <td>2016-06-06 04:47:35</td>\n",
       "      <td>2016-06-06T04:47:35Z</td>\n",
       "      <td>Asia/Shanghai</td>\n",
       "      <td>480</td>\n",
       "      <td>62</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>sleep</td>\n",
       "      <td>6960</td>\n",
       "      <td>107.400002</td>\n",
       "      <td>60.152729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>complete</td>\n",
       "      <td>2</td>\n",
       "      <td>sleep__2016-06-06T025135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            start time        start time ISO start time timezone  \\\n",
       "1  2016-06-02 16:56:58  2016-06-02T16:56:58Z       Asia/Shanghai   \n",
       "0  2016-06-03 17:07:29  2016-06-03T17:07:29Z       Asia/Shanghai   \n",
       "0  2016-06-04 18:36:17  2016-06-04T18:36:17Z       Asia/Shanghai   \n",
       "0  2016-06-05 18:20:50  2016-06-05T18:20:50Z       Asia/Shanghai   \n",
       "0  2016-06-06 02:51:35  2016-06-06T02:51:35Z       Asia/Shanghai   \n",
       "\n",
       "   start time offset             end time          end time ISO  \\\n",
       "1                480  2016-06-03 00:49:45  2016-06-03T00:49:45Z   \n",
       "0                480  2016-06-04 02:03:05  2016-06-04T02:03:05Z   \n",
       "0                480  2016-06-05 03:51:17  2016-06-05T03:51:17Z   \n",
       "0                480  2016-06-06 02:19:31  2016-06-06T02:19:31Z   \n",
       "0                480  2016-06-06 04:47:35  2016-06-06T04:47:35Z   \n",
       "\n",
       "  end time timezone  end time offset  light mins  deep mins  \\\n",
       "1     Asia/Shanghai              480         252        119   \n",
       "0     Asia/Shanghai              480         326         83   \n",
       "0     Asia/Shanghai              480         232        165   \n",
       "0     Asia/Shanghai              480         277         94   \n",
       "0     Asia/Shanghai              480          62         32   \n",
       "\n",
       "             ...             toss turns   type  actual seconds    calories  \\\n",
       "1            ...                     36  sleep           28320  437.200012   \n",
       "0            ...                     44  sleep           32100  495.100006   \n",
       "0            ...                     46  sleep           33300  513.400024   \n",
       "0            ...                     52  sleep           28680  443.100006   \n",
       "0            ...                     11  sleep            6960  107.400002   \n",
       "\n",
       "   heart rate avg heart rate min  heart rate max     state  version  \\\n",
       "1       59.062733            NaN             NaN  complete        2   \n",
       "0       67.824936            NaN             NaN  complete        2   \n",
       "0       67.653275            NaN             NaN  complete        2   \n",
       "0       61.587814            NaN             NaN  complete        2   \n",
       "0       60.152729            NaN             NaN  complete        2   \n",
       "\n",
       "                         id  \n",
       "1  sleep__2016-06-02T165658  \n",
       "0  sleep__2016-06-03T170729  \n",
       "0  sleep__2016-06-04T183617  \n",
       "0  sleep__2016-06-05T182050  \n",
       "0  sleep__2016-06-06T025135  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sallySleep = loadMetricData('sallyKung', \"sleep\")\n",
    "sallySleep.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "start time              object\n",
       "start time ISO          object\n",
       "start time timezone     object\n",
       "start time offset      float64\n",
       "end time                object\n",
       "end time ISO            object\n",
       "end time timezone       object\n",
       "end time offset        float64\n",
       "light mins             float64\n",
       "deep mins              float64\n",
       "rem mins               float64\n",
       "interruption mins      float64\n",
       "unknown mins           float64\n",
       "interruptions          float64\n",
       "toss turns             float64\n",
       "type                    object\n",
       "actual seconds         float64\n",
       "calories               float64\n",
       "heart rate avg         float64\n",
       "heart rate min         float64\n",
       "heart rate max         float64\n",
       "state                   object\n",
       "version                float64\n",
       "id                      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sallySleep.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sallyJournal = loadMetricData('sallyKung', \"journal\")\n",
    "# sallyJournal.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sallyJournal.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(292, 24)\n"
     ]
    }
   ],
   "source": [
    "# data= barbJournal.iloc[:0]\n",
    "# clean metric data\n",
    "sallyJournal[\"starttime\"]= pd.to_datetime(sallyJournal.starttime)\n",
    "\n",
    "# data= barbJournal.iloc[:1]\n",
    "sallyJournal[\"endtime\"]= pd.to_datetime(sallyJournal.endtime)\n",
    "\n",
    "\n",
    "# sarahJournal.qualitative = sarahJournal.qualitative.convert_objects(convert_numeric=True)\n",
    "# sarahJournal.excited = sarahJournal.excited.convert_objects(convert_numeric=True)\n",
    "# sarahJournal.happy = sarahJournal.happy.convert_objects(convert_numeric=True)\n",
    "\n",
    "sallyJournal.qualitative = sallyJournal.qualitative.fillna(0)\n",
    "sallyJournal.excited = sallyJournal.excited.fillna(0)\n",
    "sallyJournal.happy = sallyJournal.happy.fillna(0)\n",
    "sallyJournal.calm = sallyJournal.calm.fillna(0)\n",
    "sallyJournal.anxious = sallyJournal.anxious.fillna(0)\n",
    "sallyJournal.sad = sallyJournal.sad.fillna(0)\n",
    "sallyJournal.angry = sallyJournal.angry.fillna(0)\n",
    "sallyJournal.hungry = sallyJournal.hungry.fillna(0)\n",
    "sallyJournal.tired = sallyJournal.tired.fillna(0)\n",
    "sallyJournal.bored = sallyJournal.bored.fillna(0)\n",
    "\n",
    "print(sallyJournal.shape)\n",
    "# sallyJournal.head(5)\n",
    "# sallyJournal.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starttime</th>\n",
       "      <th>endtime</th>\n",
       "      <th>date</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>activity</th>\n",
       "      <th>location</th>\n",
       "      <th>generalemo</th>\n",
       "      <th>qualitative</th>\n",
       "      <th>excited</th>\n",
       "      <th>...</th>\n",
       "      <th>ansa</th>\n",
       "      <th>boolexcited</th>\n",
       "      <th>boolhappy</th>\n",
       "      <th>boolcalm</th>\n",
       "      <th>boolanxious</th>\n",
       "      <th>boolsad</th>\n",
       "      <th>boolangry</th>\n",
       "      <th>booltired</th>\n",
       "      <th>boolhungry</th>\n",
       "      <th>boolbored</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-05-02 13:25:00</td>\n",
       "      <td>2016-05-02 13:28:00</td>\n",
       "      <td>2016-05-02</td>\n",
       "      <td>1:25 PM</td>\n",
       "      <td>1:28 PM</td>\n",
       "      <td>Trying on watch</td>\n",
       "      <td>Barb's Office</td>\n",
       "      <td>Excited</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-05-02 13:40:00</td>\n",
       "      <td>2016-05-02 13:48:00</td>\n",
       "      <td>2016-05-02</td>\n",
       "      <td>1:40 PM</td>\n",
       "      <td>1:48 PM</td>\n",
       "      <td>Editing photos for work</td>\n",
       "      <td>Barb's Office</td>\n",
       "      <td>Streeeeeessed</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-05-02 13:48:00</td>\n",
       "      <td>2016-05-02 13:48:00</td>\n",
       "      <td>2016-05-02</td>\n",
       "      <td>1:48 PM</td>\n",
       "      <td>1:48 PM</td>\n",
       "      <td>Wafer fit perfectly on top of cup</td>\n",
       "      <td>Barb's Office</td>\n",
       "      <td>HAPPY</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-05-02 14:31:00</td>\n",
       "      <td>2016-05-02 14:50:00</td>\n",
       "      <td>2016-05-02</td>\n",
       "      <td>2:31 PM</td>\n",
       "      <td>2:50 PM</td>\n",
       "      <td>Sorting through magnetic pins</td>\n",
       "      <td>Barb's Office</td>\n",
       "      <td>Anxious</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-05-02 15:10:00</td>\n",
       "      <td>2016-05-02 15:14:00</td>\n",
       "      <td>2016-05-02</td>\n",
       "      <td>3:10 PM</td>\n",
       "      <td>3:14 PM</td>\n",
       "      <td>Trying to figure out where photos went</td>\n",
       "      <td>Barb's Office</td>\n",
       "      <td>ANXIOUS, CONFUSED</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            starttime             endtime        date    start      end  \\\n",
       "0 2016-05-02 13:25:00 2016-05-02 13:28:00  2016-05-02  1:25 PM  1:28 PM   \n",
       "1 2016-05-02 13:40:00 2016-05-02 13:48:00  2016-05-02  1:40 PM  1:48 PM   \n",
       "2 2016-05-02 13:48:00 2016-05-02 13:48:00  2016-05-02  1:48 PM  1:48 PM   \n",
       "3 2016-05-02 14:31:00 2016-05-02 14:50:00  2016-05-02  2:31 PM  2:50 PM   \n",
       "4 2016-05-02 15:10:00 2016-05-02 15:14:00  2016-05-02  3:10 PM  3:14 PM   \n",
       "\n",
       "                                 activity       location         generalemo  \\\n",
       "0                         Trying on watch  Barb's Office            Excited   \n",
       "1                 Editing photos for work  Barb's Office      Streeeeeessed   \n",
       "2       Wafer fit perfectly on top of cup  Barb's Office              HAPPY   \n",
       "3           Sorting through magnetic pins  Barb's Office            Anxious   \n",
       "4  Trying to figure out where photos went  Barb's Office  ANXIOUS, CONFUSED   \n",
       "\n",
       "   qualitative  excited    ...      ansa  boolexcited  boolhappy  boolcalm  \\\n",
       "0            8        8    ...     False         True       True     False   \n",
       "1            6        0    ...     False        False      False     False   \n",
       "2           10       10    ...     False         True       True     False   \n",
       "3            5        0    ...      True        False      False     False   \n",
       "4            9        0    ...      True        False      False     False   \n",
       "\n",
       "   boolanxious  boolsad  boolangry  booltired boolhungry boolbored  \n",
       "0        False    False      False      False      False     False  \n",
       "1        False    False      False      False      False     False  \n",
       "2        False    False      False      False      False     False  \n",
       "3         True    False       True      False      False     False  \n",
       "4         True    False      False      False      False     False  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sallyJournal['boolexcited'] =  sallyJournal['excited'] > 0\n",
    "sallyJournal['boolhappy'] =  sallyJournal['happy'] > 0\n",
    "sallyJournal['boolcalm'] =  sallyJournal['calm'] > 0\n",
    "sallyJournal['boolanxious'] =  sallyJournal['anxious'] > 0\n",
    "sallyJournal['boolsad'] =  sallyJournal['sad'] > 0\n",
    "sallyJournal['boolangry'] =  sallyJournal['angry'] > 0\n",
    "sallyJournal['booltired'] =  sallyJournal['tired'] > 0\n",
    "sallyJournal['boolhungry'] =  sallyJournal['hungry'] > 0\n",
    "sallyJournal['boolbored'] =  sallyJournal['bored'] > 0\n",
    "sallyJournal['exhaca'] =  sallyJournal['exhaca'] > 0\n",
    "sallyJournal['ansaan'] =  sallyJournal['ansaan'] > 0\n",
    "sallyJournal['exha'] =  sallyJournal['exha'] > 0\n",
    "sallyJournal['haca'] =  sallyJournal['haca'] > 0\n",
    "sallyJournal['anan'] =  sallyJournal['anan'] > 0\n",
    "sallyJournal['ansa'] =  sallyJournal['anan'] > 0\n",
    "\n",
    "    \n",
    "boolexcited = sallyJournal.iloc[:, 18].values.reshape(sallyJournal.shape[0], 1)\n",
    "boolhappy = sallyJournal.iloc[:, 19].values.reshape(sallyJournal.shape[0], 1)\n",
    "boolcalm = sallyJournal.iloc[:, 20].values.reshape(sallyJournal.shape[0], 1)\n",
    "boolanxious = sallyJournal.iloc[:, 21].values.reshape(sallyJournal.shape[0], 1)\n",
    "boolsad = sallyJournal.iloc[:, 22].values.reshape(sallyJournal.shape[0], 1)\n",
    "boolangry = sallyJournal.iloc[:, 23].values.reshape(sallyJournal.shape[0], 1)\n",
    "booltired = sallyJournal.iloc[:, 24].values.reshape(sallyJournal.shape[0], 1)\n",
    "boolhungry = sallyJournal.iloc[:, 25].values.reshape(sallyJournal.shape[0], 1)\n",
    "boolbored = sallyJournal.iloc[:, 26].values.reshape(sallyJournal.shape[0], 1)\n",
    "exhaca = sallyJournal.iloc[:, 27].values.reshape(sallyJournal.shape[0], 1)\n",
    "ansaan = sallyJournal.iloc[:, 28].values.reshape(sallyJournal.shape[0], 1)\n",
    "exha = sallyJournal.iloc[:, 29].values.reshape(sallyJournal.shape[0], 1)\n",
    "haca = sallyJournal.iloc[:, 30].values.reshape(sallyJournal.shape[0], 1)\n",
    "anan = sallyJournal.iloc[:, 31].values.reshape(sallyJournal.shape[0], 1)\n",
    "\n",
    "\n",
    "\n",
    "sallyJournal.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sallyJournal.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sallyJournal.excited.convert_objects(convert_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function that takes any journal or activity data and creates indicators for activities or emotions\n",
    "\n",
    "def makeIndicators(newvar, metricData, journalData, journal_startdatetime_loc, journal_enddatetime_loc, journal_activity_loc):\n",
    "    '''\n",
    "    Create boolean indicator variable for activities or emotions\n",
    "    newvar, string for name of new indicator variable\n",
    "    activity, string that matches the name of the activity or emotion in the journalData data frame\n",
    "    bioData, data frame of input biometric data\n",
    "    journalData, data frame of input journal or activity data\n",
    "    journal_startdatetime_loc, int of position of the start datetime in journalData\n",
    "    journal_enddatetime_loc, int of position of the end datetime in journalData\n",
    "    journal_activity_loc, int of position of the activity or emotion in journalData\n",
    "    '''\n",
    "\n",
    "    metricData[newvar] = False\n",
    "\n",
    "    for i in range(0, journalData.shape[0]):\n",
    "        metricData['xlt'] = (metricData['timestamp'] >= pd.to_datetime(journalData.iloc[i, journal_startdatetime_loc]))\n",
    "        metricData['xgt'] = (metricData['timestamp'] <= pd.to_datetime(journalData.iloc[i, journal_enddatetime_loc]))\n",
    "#         metricData['xw'] = (journalData.iloc[i, journal_activity_loc])\n",
    "        metricData['xw'] = (journalData.iloc[i, journal_activity_loc] == True)\n",
    "        metricData['xsum'] = metricData['xlt'].astype(int) + metricData['xgt'].astype(int) + metricData['xw'].astype(int)\n",
    "        metricData.loc[metricData['xsum']==3, newvar] = True\n",
    "    \n",
    "    metricData = metricData.drop(['xlt', 'xgt', 'xw', 'xsum'], axis=1)\n",
    "    return metricData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# indicator for walking\n",
    "totalData = makeIndicators('excitement', sallyMetrics, sallyJournal, 0, 1, 24)\n",
    "totalData = makeIndicators('happy', sallyMetrics, sallyJournal, 0, 1, 25)\n",
    "totalData = makeIndicators('calm', sallyMetrics, sallyJournal, 0, 1, 26)\n",
    "totalData = makeIndicators('anxious', sallyMetrics, sallyJournal, 0, 1, 27)\n",
    "totalData = makeIndicators('sad', sallyMetrics, sallyJournal, 0, 1, 28)\n",
    "totalData = makeIndicators('angry', sallyMetrics, sallyJournal, 0, 1, 29)\n",
    "totalData = makeIndicators('hungry', sallyMetrics, sallyJournal, 0, 1, 30)\n",
    "totalData = makeIndicators('tired', sallyMetrics, sallyJournal, 0, 1, 31)\n",
    "totalData = makeIndicators('bored', sallyMetrics, sallyJournal, 0, 1, 32)\n",
    "\n",
    "\n",
    "totalData = makeIndicators('exhaca', sallyMetrics, sallyJournal, 0, 1, 27)\n",
    "totalData = makeIndicators('ansaan', sallyMetrics, sallyJournal, 0, 1, 28)\n",
    "\n",
    "totalData = makeIndicators('exha', sallyMetrics, sallyJournal, 0, 1, 29)\n",
    "totalData = makeIndicators('haca', sallyMetrics, sallyJournal, 0, 1, 30)\n",
    "totalData = makeIndicators('anan', sallyMetrics, sallyJournal, 0, 1, 31)\n",
    "totalData = makeIndicators('ansa', sallyMetrics, sallyJournal, 0, 1, 32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          heartrate         steps      calories           gsr      skintemp  \\\n",
      "count  43920.000000  43920.000000  43920.000000  43920.000000  43920.000000   \n",
      "mean      77.215255      7.071061      1.633281      0.009605     82.985501   \n",
      "std       24.908041     23.241126      1.194595      0.163470     21.224387   \n",
      "min        0.000000      0.000000      0.600000      0.000000      0.000000   \n",
      "25%       65.000000      0.000000      1.000000      0.000054     85.100000   \n",
      "50%       79.000000      0.000000      1.200000      0.000059     88.700000   \n",
      "75%       92.000000      0.000000      1.709000      0.000072     90.500000   \n",
      "max      169.000000    143.000000     12.000000     17.100000    100.400000   \n",
      "\n",
      "            airtemp excitement      happy      calm    anxious    ...      \\\n",
      "count  43920.000000      43920      43920     43920      43920    ...       \n",
      "mean      79.940501  0.0176002  0.0346995  0.123042  0.0623179    ...       \n",
      "std       20.560615   0.131495    0.18302  0.328489   0.241735    ...       \n",
      "min        0.000000      False      False     False      False    ...       \n",
      "25%       81.500000          0          0         0          0    ...       \n",
      "50%       84.200000          0          0         0          0    ...       \n",
      "75%       87.800000          0          0         0          0    ...       \n",
      "max      100.400000       True       True      True       True    ...       \n",
      "\n",
      "           angry    hungry       tired      bored     exhaca     ansaan  \\\n",
      "count      43920     43920       43920      43920      43920      43920   \n",
      "mean   0.0296903  0.134654  0.00280055  0.0400273  0.0623179  0.0015255   \n",
      "std     0.169734  0.341357   0.0528466   0.196026   0.241735  0.0390283   \n",
      "min        False     False       False      False      False      False   \n",
      "25%            0         0           0          0          0          0   \n",
      "50%            0         0           0          0          0          0   \n",
      "75%            0         0           0          0          0          0   \n",
      "max         True      True        True       True       True       True   \n",
      "\n",
      "            exha      haca        anan       ansa  \n",
      "count      43920     43920       43920      43920  \n",
      "mean   0.0296903  0.134654  0.00280055  0.0400273  \n",
      "std     0.169734  0.341357   0.0528466   0.196026  \n",
      "min        False     False       False      False  \n",
      "25%            0         0           0          0  \n",
      "50%            0         0           0          0  \n",
      "75%            0         0           0          0  \n",
      "max         True      True        True       True  \n",
      "\n",
      "[8 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "print(totalData.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            timestamp  heartrate  steps  calories  gsr  skintemp  airtemp  \\\n",
      "0 2016-05-02 00:00:00          0      4     1.709    0         0        0   \n",
      "1 2016-05-02 00:01:00          0      4     1.709    0         0        0   \n",
      "2 2016-05-02 00:02:00          0      4     1.709    0         0        0   \n",
      "3 2016-05-02 00:03:00          0      4     1.709    0         0        0   \n",
      "4 2016-05-02 00:04:00          0      4     1.709    0         0        0   \n",
      "\n",
      "  excitement  happy   calm  ...    angry hungry  tired  bored exhaca ansaan  \\\n",
      "0      False  False  False  ...    False  False  False  False  False  False   \n",
      "1      False  False  False  ...    False  False  False  False  False  False   \n",
      "2      False  False  False  ...    False  False  False  False  False  False   \n",
      "3      False  False  False  ...    False  False  False  False  False  False   \n",
      "4      False  False  False  ...    False  False  False  False  False  False   \n",
      "\n",
      "    exha   haca   anan   ansa  \n",
      "0  False  False  False  False  \n",
      "1  False  False  False  False  \n",
      "2  False  False  False  False  \n",
      "3  False  False  False  False  \n",
      "4  False  False  False  False  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "print(totalData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "totalData.to_csv('sallyTotal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>steps</th>\n",
       "      <th>calories</th>\n",
       "      <th>gsr</th>\n",
       "      <th>skintemp</th>\n",
       "      <th>airtemp</th>\n",
       "      <th>excitement</th>\n",
       "      <th>happy</th>\n",
       "      <th>calm</th>\n",
       "      <th>...</th>\n",
       "      <th>angry</th>\n",
       "      <th>hungry</th>\n",
       "      <th>tired</th>\n",
       "      <th>bored</th>\n",
       "      <th>exhaca</th>\n",
       "      <th>ansaan</th>\n",
       "      <th>exha</th>\n",
       "      <th>haca</th>\n",
       "      <th>anan</th>\n",
       "      <th>ansa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-05-02 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-05-02 00:01:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-05-02 00:02:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-05-02 00:03:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-05-02 00:04:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  heartrate  steps  calories  gsr  skintemp  airtemp  \\\n",
       "0 2016-05-02 00:00:00          0      4     1.709    0         0        0   \n",
       "1 2016-05-02 00:01:00          0      4     1.709    0         0        0   \n",
       "2 2016-05-02 00:02:00          0      4     1.709    0         0        0   \n",
       "3 2016-05-02 00:03:00          0      4     1.709    0         0        0   \n",
       "4 2016-05-02 00:04:00          0      4     1.709    0         0        0   \n",
       "\n",
       "  excitement  happy   calm  ...    angry hungry  tired  bored exhaca ansaan  \\\n",
       "0      False  False  False  ...    False  False  False  False  False  False   \n",
       "1      False  False  False  ...    False  False  False  False  False  False   \n",
       "2      False  False  False  ...    False  False  False  False  False  False   \n",
       "3      False  False  False  ...    False  False  False  False  False  False   \n",
       "4      False  False  False  ...    False  False  False  False  False  False   \n",
       "\n",
       "    exha   haca   anan   ansa  \n",
       "0  False  False  False  False  \n",
       "1  False  False  False  False  \n",
       "2  False  False  False  False  \n",
       "3  False  False  False  False  \n",
       "4  False  False  False  False  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalData.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43920, 26)\n",
      "            timestamp  heartrate  steps  calories  gsr  skintemp  airtemp  \\\n",
      "0 2016-05-02 00:00:00          0      4     1.709    0         0        0   \n",
      "1 2016-05-02 00:01:00          0      4     1.709    0         0        0   \n",
      "2 2016-05-02 00:02:00          0      4     1.709    0         0        0   \n",
      "3 2016-05-02 00:03:00          0      4     1.709    0         0        0   \n",
      "4 2016-05-02 00:04:00          0      4     1.709    0         0        0   \n",
      "\n",
      "  excitement  happy   calm ... exhaca ansaan   exha   haca   anan   ansa  \\\n",
      "0      False  False  False ...  False  False  False  False  False  False   \n",
      "1      False  False  False ...  False  False  False  False  False  False   \n",
      "2      False  False  False ...  False  False  False  False  False  False   \n",
      "3      False  False  False ...  False  False  False  False  False  False   \n",
      "4      False  False  False ...  False  False  False  False  False  False   \n",
      "\n",
      "  weekday month hour min  \n",
      "0       0     5    0   0  \n",
      "1       0     5    0   1  \n",
      "2       0     5    0   2  \n",
      "3       0     5    0   3  \n",
      "4       0     5    0   4  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# find day of week (0-6, Mon-Sun)\n",
    "totalData['weekday'] = totalData['timestamp'].dt.weekday\n",
    "totalData['month'] = totalData['timestamp'].dt.month\n",
    "totalData['hour'] = totalData['timestamp'].dt.hour\n",
    "totalData['min'] = totalData['timestamp'].dt.minute\n",
    "\n",
    "\n",
    "print(totalData.shape)\n",
    "print(totalData.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " ..., \n",
      " [23]\n",
      " [23]\n",
      " [23]]\n"
     ]
    }
   ],
   "source": [
    "heartrate = totalData.iloc[:, 1].values.reshape(totalData.shape[0], 1)\n",
    "steps = totalData.iloc[:, 2].values.reshape(totalData.shape[0], 1)\n",
    "calories = totalData.iloc[:, 3].values.reshape(totalData.shape[0], 1)\n",
    "gsr = totalData.iloc[:, 4].values.reshape(totalData.shape[0], 1)\n",
    "skintemp = totalData.iloc[:, 5].values.reshape(totalData.shape[0], 1)\n",
    "airtemp = totalData.iloc[:, 6].values.reshape(totalData.shape[0], 1)\n",
    "\n",
    "# DayOfWeek = totalData.iloc[:, 25].values.reshape(totalData.shape[0], 1)\n",
    "# Month = totalData.iloc[:, 26].values.reshape(totalData.shape[0], 1)\n",
    "weekday = totalData['weekday'].values.reshape(totalData.shape[0], 1)\n",
    "month = totalData['month'].values.reshape(totalData.shape[0], 1)\n",
    "hour = totalData['hour'].values.reshape(totalData.shape[0], 1)\n",
    "# curmin = totalData['min'].values.reshape(totalData.shape[0], 1)\n",
    "\n",
    "print(hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43920, 8)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate to numpy dataset\n",
    "X = np.concatenate((\n",
    "        heartrate, \n",
    "        steps, \n",
    "        calories, \n",
    "        gsr, \n",
    "        skintemp, \n",
    "        airtemp,\n",
    "        weekday,\n",
    "#         month,\n",
    "        hour\n",
    "#         curmin\n",
    "    ), axis=1)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43920,)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define y\n",
    "y = totalData.excitement.values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# report on training and test sets\n",
    "global SVMerror, SVMacc, SVMtp, SVMtn, LRerror, LRacc, LRtp, LRtn, NBerror, NBacc, NBtp, NBtn, Perror, Pacc, Ptp, Ptn\n",
    "\n",
    "\n",
    "\n",
    "def print_results(model):\n",
    "    #print('Error rate on training set: ')\n",
    "    erTRAIN = ((y_train != y_pred).sum() / X_train.shape[0])\n",
    "    #print('Accuracy rate on training set: ')\n",
    "    AccTRAIN = (1 - (y_train != y_pred).sum() / X_train.shape[0])\n",
    "    #print('True positive rate on training tet:')\n",
    "    TruPosTRAIN = ((y_train==True) & (y_pred==True)).sum() / y_train.sum()\n",
    "    #TruNegTEST = (((y_train==False) & (y_pred_train==False)).sum() / (y_train.shape[0] - y_train.sum()))\n",
    "    #print('**************')\n",
    "    #('Error rate on test set: ')\n",
    "    erTEST = ((y_test != y_pred_test).sum() / X_test.shape[0])\n",
    "    #print('Accuracy rate on test set: ')\n",
    "    AccTEST = (1 - (y_test != y_pred_test).sum() / X_test.shape[0])\n",
    "    #print('True positive rate on test set')\n",
    "    TruPosTEST = (((y_test==True) & (y_pred_test==True)).sum() / y_test.sum())\n",
    "    #print('True negative rate on test set')\n",
    "    TruNegTEST = (((y_test==False) & (y_pred_test==False)).sum() / (y_test.shape[0] - y_test.sum()))\n",
    "    data_rows = [('Error Rate', erTRAIN, erTEST),\n",
    "                 ('Accuracy Rate', AccTRAIN, AccTEST),\n",
    "                 ('True Positives', TruPosTRAIN, TruPosTEST),\n",
    "                 ('True Negatives', '--', TruNegTEST)]\n",
    "    t = Table(rows=data_rows, names=(model, 'Training Set', 'Test Set'), meta={'name': model + ': Training and Test Set Results'})\n",
    "    print(t)\n",
    "    if model == 'SVM':\n",
    "        SVMerror = erTEST\n",
    "        SVMacc = AccTEST\n",
    "        SVMtp = TruPosTEST\n",
    "        SVMtn = TruNegTEST\n",
    "        return(SVMerror, SVMacc, SVMtp, SVMtn)\n",
    "    elif model == 'Logistic Regression':\n",
    "        LRerror = erTEST\n",
    "        LRacc = AccTEST\n",
    "        LRtp = TruPosTEST\n",
    "        LRtn = TruNegTEST\n",
    "        return(LRerror, LRacc, LRtp, LRtn)\n",
    "    elif model == 'Naive Bayes':\n",
    "        NBerror = erTEST\n",
    "        NBacc = AccTEST\n",
    "        NBtp = TruPosTEST\n",
    "        NBtn = TruNegTEST\n",
    "        return(NBerror, NBacc, NBtp, NBtn)\n",
    "    elif model == 'Perceptron':\n",
    "        Perror = erTEST\n",
    "        Pacc = AccTEST\n",
    "        Ptp = TruPosTEST\n",
    "        Ptn = TruNegTEST\n",
    "        return(Perror, Pacc, Ptp, Ptn)\n",
    "    print('done')\n",
    "      \n",
    "    #t.show_in_browser(jsviewer=True) \n",
    "    \n",
    "    \n",
    "def all_models_table():\n",
    "    all_rows = [('SVM', SVMerror, SVMacc, SVMtp, SVMtn),\n",
    "            ('Logistic Regression', LRerror, LRacc, LRtp, LRtn),\n",
    "            ('Naive Bayes', NBerror, NBacc, NBtp, NBtn),\n",
    "            ('Perceptron', Perror, Pacc, Ptp, Ptn)]\n",
    "    tt = Table(rows=all_rows, names=('', 'Error Rate', 'Accuracy', 'True +', 'True -'), meta={'3/15/2016'})\n",
    "    print(tt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excited Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SVM         Training Set      Test Set   \n",
      "-------------- --------------- ---------------\n",
      "    Error Rate 0.0173041894353 0.0182908318154\n",
      " Accuracy Rate  0.982695810565  0.981709168185\n",
      "True Positives             0.0             0.0\n",
      "True Negatives              --             1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.01829083181542198, 0.98170916818457798, 0.0, 1.0)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: SVM, linear\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression   Training Set      Test Set   \n",
      "------------------- --------------- ---------------\n",
      "         Error Rate 0.0173041894353 0.0182908318154\n",
      "      Accuracy Rate  0.982695810565  0.981709168185\n",
      "     True Positives             0.0             0.0\n",
      "     True Negatives              --             1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.01829083181542198, 0.98170916818457798, 0.0, 1.0)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: logistic regression\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Naive Bayes     Training Set      Test Set   \n",
      "-------------- --------------- ---------------\n",
      "    Error Rate 0.0173041894353 0.0182908318154\n",
      " Accuracy Rate  0.982695810565  0.981709168185\n",
      "True Positives             0.0             0.0\n",
      "True Negatives              --             1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.01829083181542198, 0.98170916818457798, 0.0, 1.0)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Perceptron     Training Set      Test Set   \n",
      "-------------- --------------- ---------------\n",
      "    Error Rate 0.0238095238095 0.0245901639344\n",
      " Accuracy Rate   0.97619047619  0.975409836066\n",
      "True Positives 0.0131578947368 0.0207468879668\n",
      "True Negatives              --  0.993196752996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.024590163934426229,\n",
       " 0.97540983606557374,\n",
       " 0.020746887966804978,\n",
       " 0.99319675299574794)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='perceptron')\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Perceptron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43920,)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define y\n",
    "y = totalData.happy.values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Happy Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SVM        Training Set      Test Set   \n",
      "-------------- -------------- ---------------\n",
      "    Error Rate 0.053181108509 0.0598816029144\n",
      " Accuracy Rate 0.946818891491  0.940118397086\n",
      "True Positives 0.109126984127  0.124031007752\n",
      "True Negatives             --  0.973380726698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.059881602914389799,\n",
       " 0.94011839708561018,\n",
       " 0.12403100775193798,\n",
       " 0.97338072669826226)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: SVM, linear\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression  Training Set      Test Set   \n",
      "------------------- -------------- ---------------\n",
      "         Error Rate 0.057702315899 0.0638281724347\n",
      "      Accuracy Rate 0.942297684101  0.936171827565\n",
      "     True Positives 0.144841269841  0.160852713178\n",
      "     True Negatives             --  0.967772511848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.06382817243472981,\n",
       " 0.93617182756527018,\n",
       " 0.16085271317829458,\n",
       " 0.96777251184834123)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: logistic regression\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Naive Bayes     Training Set      Test Set   \n",
      "-------------- --------------- ---------------\n",
      "    Error Rate 0.0328194119178 0.0391621129326\n",
      " Accuracy Rate  0.967180588082  0.960837887067\n",
      "True Positives             0.0             0.0\n",
      "True Negatives              --             1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.039162112932604735, 0.96083788706739526, 0.0, 1.0)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Perceptron     Training Set      Test Set   \n",
      "-------------- --------------- ---------------\n",
      "    Error Rate 0.0547098620869 0.0600333940498\n",
      " Accuracy Rate  0.945290137913   0.93996660595\n",
      "True Positives 0.0922619047619  0.110465116279\n",
      "True Negatives              --  0.973775671406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.06003339404978749,\n",
       " 0.93996660595021253,\n",
       " 0.11046511627906977,\n",
       " 0.97377567140600318)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='perceptron')\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Perceptron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43920,)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define y\n",
    "y = totalData.calm.values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calm Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SVM         Training Set     Test Set   \n",
      "-------------- --------------- --------------\n",
      "    Error Rate  0.132285974499 0.128794778385\n",
      " Accuracy Rate  0.867714025501 0.871205221615\n",
      "True Positives 0.0147058823529 0.016290726817\n",
      "True Negatives              -- 0.989032815199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.12879477838494233,\n",
       " 0.87120522161505765,\n",
       " 0.016290726817042606,\n",
       " 0.9890328151986183)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: SVM, linear\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression   Training Set       Test Set    \n",
      "------------------- ---------------- ----------------\n",
      "         Error Rate   0.129228467343   0.127276867031\n",
      "      Accuracy Rate   0.870771532657   0.872723132969\n",
      "     True Positives 0.00735294117647 0.00877192982456\n",
      "     True Negatives               --   0.991796200345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.12727686703096538,\n",
       " 0.87272313296903459,\n",
       " 0.008771929824561403,\n",
       " 0.99179620034542315)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: logistic regression\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Naive Bayes     Training Set       Test Set    \n",
      "-------------- ---------------- ----------------\n",
      "    Error Rate   0.124414519906   0.121736490589\n",
      " Accuracy Rate   0.875585480094   0.878263509411\n",
      "True Positives 0.00078781512605 0.00062656641604\n",
      "True Negatives               --   0.999222797927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.1217364905889496,\n",
       " 0.87826350941105036,\n",
       " 0.00062656641604010022,\n",
       " 0.99922279792746116)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Perceptron     Training Set       Test Set    \n",
      "-------------- ---------------- ----------------\n",
      "    Error Rate   0.127211813687   0.124620522162\n",
      " Accuracy Rate   0.872788186313   0.875379477838\n",
      "True Positives 0.00341386554622 0.00375939849624\n",
      "True Negatives               --   0.995509499136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.12462052216150576,\n",
       " 0.87537947783849424,\n",
       " 0.0037593984962406013,\n",
       " 0.99550949913644216)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='perceptron')\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Perceptron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43920,)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define y\n",
    "y = totalData.anxious.values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anxious Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SVM        Training Set     Test Set   \n",
      "-------------- -------------- --------------\n",
      "    Error Rate 0.252179287015 0.258120825744\n",
      " Accuracy Rate 0.747820712985 0.741879174256\n",
      "True Positives 0.517847629196 0.497674418605\n",
      "True Negatives             -- 0.758931471257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.25812082574377654,\n",
       " 0.74187917425622341,\n",
       " 0.49767441860465117,\n",
       " 0.75893147125690164)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: SVM, linear\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression   Training Set     Test Set   \n",
      "------------------- --------------- --------------\n",
      "         Error Rate 0.0610525631017 0.065270188221\n",
      "      Accuracy Rate  0.938947436898 0.934729811779\n",
      "     True Positives             0.0            0.0\n",
      "     True Negatives              --            1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.065270188221007899, 0.93472981177899206, 0.0, 1.0)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: logistic regression\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Naive Bayes     Training Set      Test Set    \n",
      "-------------- --------------- ----------------\n",
      "    Error Rate 0.0622235232891  0.0664086217365\n",
      " Accuracy Rate  0.937776476711   0.933591378264\n",
      "True Positives 0.0042621204049 0.00348837209302\n",
      "True Negatives              --   0.998538486522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.066408621736490592,\n",
       " 0.93359137826350946,\n",
       " 0.0034883720930232558,\n",
       " 0.99853848652159793)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Perceptron     Training Set      Test Set   \n",
      "-------------- --------------- ---------------\n",
      "    Error Rate 0.0836260733802 0.0884942319369\n",
      " Accuracy Rate   0.91637392662  0.911505768063\n",
      "True Positives  0.125199786894  0.123255813953\n",
      "True Negatives              --  0.966547580383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.088494231936854892,\n",
       " 0.91150576806314509,\n",
       " 0.12325581395348838,\n",
       " 0.96654758038324129)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='perceptron')\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Perceptron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43920,)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define y\n",
    "y = totalData.sad.values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sad Model Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SVM         Training Set       Test Set    \n",
      "-------------- ---------------- ----------------\n",
      "    Error Rate 0.00162633359355 0.00129022465088\n",
      " Accuracy Rate   0.998373666406   0.998709775349\n",
      "True Positives              0.0              0.0\n",
      "True Negatives               --              1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0012902246508803886, 0.99870977534911964, 0.0, 1.0)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: SVM, linear\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression   Training Set       Test Set    \n",
      "------------------- ---------------- ----------------\n",
      "         Error Rate 0.00169138693729 0.00144201578628\n",
      "      Accuracy Rate   0.998308613063   0.998557984214\n",
      "     True Positives              0.0              0.0\n",
      "     True Negatives               --   0.999848012767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0014420157862780813, 0.99855798421372188, 0.0, 0.99984801276692759)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: logistic regression\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Naive Bayes     Training Set       Test Set    \n",
      "-------------- ---------------- ----------------\n",
      "    Error Rate 0.00162633359355 0.00129022465088\n",
      " Accuracy Rate   0.998373666406   0.998709775349\n",
      "True Positives              0.0              0.0\n",
      "True Negatives               --              1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0012902246508803886, 0.99870977534911964, 0.0, 1.0)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Perceptron     Training Set       Test Set    \n",
      "-------------- ---------------- ----------------\n",
      "    Error Rate 0.00162633359355 0.00129022465088\n",
      " Accuracy Rate   0.998373666406   0.998709775349\n",
      "True Positives              0.0              0.0\n",
      "True Negatives               --              1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0012902246508803886, 0.99870977534911964, 0.0, 1.0)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='perceptron')\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Perceptron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43920,)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define y\n",
    "y = totalData.angry.values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Angry Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SVM         Training Set      Test Set   \n",
      "-------------- --------------- ---------------\n",
      "    Error Rate 0.0290463179807 0.0311930783242\n",
      " Accuracy Rate  0.970953682019  0.968806921676\n",
      "True Positives             0.0             0.0\n",
      "True Negatives              --             1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.031193078324225864, 0.96880692167577409, 0.0, 1.0)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: SVM, linear\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression   Training Set      Test Set   \n",
      "------------------- --------------- ---------------\n",
      "         Error Rate 0.0290463179807 0.0311930783242\n",
      "      Accuracy Rate  0.970953682019  0.968806921676\n",
      "     True Positives             0.0             0.0\n",
      "     True Negatives              --             1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.031193078324225864, 0.96880692167577409, 0.0, 1.0)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: logistic regression\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Naive Bayes     Training Set      Test Set   \n",
      "-------------- --------------- ---------------\n",
      "    Error Rate 0.0290463179807 0.0311930783242\n",
      " Accuracy Rate  0.970953682019  0.968806921676\n",
      "True Positives             0.0             0.0\n",
      "True Negatives              --             1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.031193078324225864, 0.96880692167577409, 0.0, 1.0)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Perceptron     Training Set      Test Set   \n",
      "-------------- --------------- ---------------\n",
      "    Error Rate 0.0333723653396 0.0355950212508\n",
      " Accuracy Rate   0.96662763466  0.964404978749\n",
      "True Positives 0.0279955207167 0.0170316301703\n",
      "True Negatives              --   0.99490795143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.035595021250758953,\n",
       " 0.96440497874924103,\n",
       " 0.017031630170316302,\n",
       " 0.99490795142969057)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='perceptron')\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Perceptron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43920,)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define y\n",
    "y = totalData.hungry.values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hungry Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SVM        Training Set     Test Set  \n",
      "-------------- -------------- -------------\n",
      "    Error Rate 0.134270101483 0.13554948391\n",
      " Accuracy Rate 0.865729898517 0.86445051609\n",
      "True Positives            0.0           0.0\n",
      "True Negatives             --           1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.13554948391013966, 0.86445051608986034, 0.0, 1.0)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: SVM, linear\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression  Training Set     Test Set   \n",
      "------------------- -------------- --------------\n",
      "         Error Rate 0.596766848816 0.596387370978\n",
      "      Accuracy Rate 0.403233151184 0.403612629022\n",
      "     True Positives 0.858769379845 0.879059350504\n",
      "     True Negatives             -- 0.329060579456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.59638737097753491,\n",
       " 0.40361262902246509,\n",
       " 0.87905935050391937,\n",
       " 0.32906057945566286)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: logistic regression\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Naive Bayes     Training Set       Test Set    \n",
      "-------------- ---------------- ----------------\n",
      "    Error Rate   0.138140775436   0.138357619915\n",
      " Accuracy Rate   0.861859224564   0.861642380085\n",
      "True Positives 0.00654069767442 0.00951847704367\n",
      "True Negatives               --   0.995258999122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.13835761991499695,\n",
       " 0.86164238008500305,\n",
       " 0.0095184770436730123,\n",
       " 0.99525899912203686)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Perceptron     Training Set       Test Set    \n",
      "-------------- ---------------- ----------------\n",
      "    Error Rate   0.137295081967   0.138281724347\n",
      " Accuracy Rate   0.862704918033   0.861718275653\n",
      "True Positives 0.00290697674419 0.00391937290034\n",
      "True Negatives               --    0.99622475856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.13828172434729813,\n",
       " 0.86171827565270187,\n",
       " 0.0039193729003359464,\n",
       " 0.99622475856014048)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='perceptron')\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Perceptron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43920,)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define y\n",
    "y = totalData.tired.values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tired Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SVM         Training Set       Test Set    \n",
      "-------------- ---------------- ----------------\n",
      "    Error Rate 0.00286234712464 0.00265634486946\n",
      " Accuracy Rate   0.997137652875   0.997343655131\n",
      "True Positives              0.0              0.0\n",
      "True Negatives               --              1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0026563448694596234, 0.99734365513054035, 0.0, 1.0)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: SVM, linear\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression   Training Set       Test Set    \n",
      "------------------- ---------------- ----------------\n",
      "         Error Rate 0.00354540723393 0.00318761384335\n",
      "      Accuracy Rate   0.996454592766   0.996812386157\n",
      "     True Positives  0.0113636363636  0.0285714285714\n",
      "     True Negatives               --   0.999391218324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0031876138433515485,\n",
       " 0.99681238615664847,\n",
       " 0.028571428571428571,\n",
       " 0.99939121832432842)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: logistic regression\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Naive Bayes     Training Set       Test Set    \n",
      "-------------- ---------------- ----------------\n",
      "    Error Rate 0.00286234712464 0.00265634486946\n",
      " Accuracy Rate   0.997137652875   0.997343655131\n",
      "True Positives              0.0              0.0\n",
      "True Negatives               --              1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0026563448694596234, 0.99734365513054035, 0.0, 1.0)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Perceptron     Training Set       Test Set    \n",
      "-------------- ---------------- ----------------\n",
      "    Error Rate 0.00286234712464 0.00265634486946\n",
      " Accuracy Rate   0.997137652875   0.997343655131\n",
      "True Positives              0.0              0.0\n",
      "True Negatives               --              1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0026563448694596234, 0.99734365513054035, 0.0, 1.0)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='perceptron')\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Perceptron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43920,)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define y\n",
    "y = totalData.bored.values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bored Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SVM         Training Set      Test Set    \n",
      "-------------- --------------- ----------------\n",
      "    Error Rate 0.0437809003383  0.0395415907711\n",
      " Accuracy Rate  0.956219099662   0.960458409229\n",
      "True Positives             0.0 0.00202429149798\n",
      "True Negatives              --   0.997792146349\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.039541590771098971,\n",
       " 0.96045840922890102,\n",
       " 0.0020242914979757085,\n",
       " 0.99779214634915625)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: SVM, linear\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression   Training Set      Test Set   \n",
      "------------------- --------------- ---------------\n",
      "         Error Rate  0.054189435337 0.0506223436551\n",
      "      Accuracy Rate  0.945810564663  0.949377656345\n",
      "     True Positives 0.0435126582278 0.0364372469636\n",
      "     True Negatives              --  0.984939284025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.05062234365513054,\n",
       " 0.94937765634486948,\n",
       " 0.03643724696356275,\n",
       " 0.98493928402460185)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: logistic regression\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Naive Bayes     Training Set      Test Set   \n",
      "-------------- --------------- ---------------\n",
      "    Error Rate 0.0411137132449 0.0374924104432\n",
      " Accuracy Rate  0.958886286755  0.962507589557\n",
      "True Positives             0.0             0.0\n",
      "True Negatives              --             1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.037492410443230116, 0.96250758955676985, 0.0, 1.0)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Perceptron     Training Set      Test Set    \n",
      "-------------- --------------- ----------------\n",
      "    Error Rate 0.0420244600572  0.0382513661202\n",
      " Accuracy Rate  0.957975539943    0.96174863388\n",
      "True Positives             0.0 0.00202429149798\n",
      "True Negatives              --   0.999132628923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.03825136612021858,\n",
       " 0.96174863387978138,\n",
       " 0.0020242914979757085,\n",
       " 0.99913262892288279)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='perceptron')\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Perceptron')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positive ( Excited, Happy, Calm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43920,)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define y\n",
    "\n",
    "\n",
    "y = totalData.exhaca.values\n",
    "\n",
    "# y = totalData.excitement.values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "#\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive ( Excited, Happy, Calm) Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SVM         Training Set      Test Set   \n",
      "-------------- --------------- ---------------\n",
      "    Error Rate 0.0725995316159 0.0765027322404\n",
      " Accuracy Rate  0.927400468384   0.92349726776\n",
      "True Positives 0.0303676078849 0.0313953488372\n",
      "True Negatives              --  0.985790841182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.07650273224043716,\n",
       " 0.92349726775956287,\n",
       " 0.031395348837209305,\n",
       " 0.98579084118220206)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: SVM, linear\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)\n",
    "print_results('SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression   Training Set      Test Set   \n",
      "------------------- --------------- ---------------\n",
      "         Error Rate 0.0890905542545 0.0916818457802\n",
      "      Accuracy Rate  0.910909445746   0.90831815422\n",
      "     True Positives  0.101225359616  0.109302325581\n",
      "     True Negatives              --  0.964111724586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.091681845780206439,\n",
       " 0.90831815421979356,\n",
       " 0.10930232558139535,\n",
       " 0.96411172458590455)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: logistic regression\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression   Training Set      Test Set   \n",
      "------------------- --------------- ---------------\n",
      "         Error Rate 0.0874316939891 0.0915300546448\n",
      "      Accuracy Rate  0.912568306011  0.908469945355\n",
      "     True Positives  0.159296750133  0.160465116279\n",
      "     True Negatives              --   0.96070152647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.091530054644808748,\n",
       " 0.90846994535519121,\n",
       " 0.16046511627906976,\n",
       " 0.96070152646963303)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: logistic regression\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='log', n_iter=50000, alpha=0.0001)\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)\n",
    "print_results('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(clf.coef_)\n",
    "# print(clf.intercept_)\n",
    "# print(X_train_std[0:5])\n",
    "# print(X_train[0:5])\n",
    "# heartrate, steps, calories, gsr, skintemp, airtemp, weekday, hour, curmin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Naive Bayes     Training Set      Test Set    \n",
      "-------------- --------------- ----------------\n",
      "    Error Rate 0.0622235232891  0.0664086217365\n",
      " Accuracy Rate  0.937776476711   0.933591378264\n",
      "True Positives 0.0042621204049 0.00348837209302\n",
      "True Negatives              --   0.998538486522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.066408621736490592,\n",
       " 0.93359137826350946,\n",
       " 0.0034883720930232558,\n",
       " 0.99853848652159793)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Perceptron     Training Set      Test Set   \n",
      "-------------- --------------- ---------------\n",
      "    Error Rate 0.0923106947697 0.0961596842744\n",
      " Accuracy Rate   0.90768930523  0.903840315726\n",
      "True Positives  0.151305274374  0.145348837209\n",
      "True Negatives              --  0.956804157194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.09615968427443837,\n",
       " 0.90384031572556167,\n",
       " 0.14534883720930233,\n",
       " 0.95680415719389411)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='perceptron')\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Perceptron')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negative ( Anxious, Sad, Angry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43920,)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define y\n",
    "y = totalData.ansaan.values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative ( Anxious, Sad, Angry) Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SVM         Training Set       Test Set    \n",
      "-------------- ---------------- ----------------\n",
      "    Error Rate 0.00162633359355 0.00129022465088\n",
      " Accuracy Rate   0.998373666406   0.998709775349\n",
      "True Positives              0.0              0.0\n",
      "True Negatives               --              1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0012902246508803886, 0.99870977534911964, 0.0, 1.0)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: SVM, linear\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression   Training Set      Test Set    \n",
      "------------------- --------------- ----------------\n",
      "         Error Rate 0.0017889669529 0.00144201578628\n",
      "      Accuracy Rate  0.998211033047   0.998557984214\n",
      "     True Positives             0.0              0.0\n",
      "     True Negatives              --   0.999848012767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0014420157862780813, 0.99855798421372188, 0.0, 0.99984801276692759)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: logistic regression\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Naive Bayes     Training Set       Test Set    \n",
      "-------------- ---------------- ----------------\n",
      "    Error Rate 0.00162633359355 0.00129022465088\n",
      " Accuracy Rate   0.998373666406   0.998709775349\n",
      "True Positives              0.0              0.0\n",
      "True Negatives               --              1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0012902246508803886, 0.99870977534911964, 0.0, 1.0)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Perceptron     Training Set       Test Set    \n",
      "-------------- ---------------- ----------------\n",
      "    Error Rate 0.00162633359355 0.00129022465088\n",
      " Accuracy Rate   0.998373666406   0.998709775349\n",
      "True Positives              0.0              0.0\n",
      "True Negatives               --              1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0012902246508803886, 0.99870977534911964, 0.0, 1.0)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='perceptron')\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Perceptron')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Happy/Calm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43920,)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define y\n",
    "y = totalData.haca.values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Happy/Calm  Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SVM        Training Set     Test Set   \n",
      "-------------- -------------- --------------\n",
      "    Error Rate  0.20706479313 0.209699453552\n",
      " Accuracy Rate  0.79293520687 0.790300546448\n",
      "True Positives 0.164728682171 0.159574468085\n",
      "True Negatives             -- 0.889201053556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.20969945355191258,\n",
       " 0.79030054644808745,\n",
       " 0.15957446808510639,\n",
       " 0.88920105355575063)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: SVM, linear\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression  Training Set     Test Set  \n",
      "------------------- -------------- -------------\n",
      "         Error Rate 0.134270101483 0.13554948391\n",
      "      Accuracy Rate 0.865729898517 0.86445051609\n",
      "     True Positives            0.0           0.0\n",
      "     True Negatives             --           1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.13554948391013966, 0.86445051608986034, 0.0, 1.0)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: logistic regression\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Naive Bayes     Training Set       Test Set    \n",
      "-------------- ---------------- ----------------\n",
      "    Error Rate   0.138140775436   0.138357619915\n",
      " Accuracy Rate   0.861859224564   0.861642380085\n",
      "True Positives 0.00654069767442 0.00951847704367\n",
      "True Negatives               --   0.995258999122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.13835761991499695,\n",
       " 0.86164238008500305,\n",
       " 0.0095184770436730123,\n",
       " 0.99525899912203686)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Perceptron    Training Set      Test Set   \n",
      "-------------- -------------- ---------------\n",
      "    Error Rate 0.806075982305  0.801760777171\n",
      " Accuracy Rate 0.193924017695  0.198239222829\n",
      "True Positives 0.989825581395  0.991041433371\n",
      "True Negatives             -- 0.0739244951712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.80176077717061323,\n",
       " 0.19823922282938677,\n",
       " 0.99104143337066064,\n",
       " 0.073924495171202809)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='perceptron')\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Perceptron')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anxious/Angry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43920,)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define y\n",
    "y = totalData.anan.values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SVM         Training Set       Test Set    \n",
      "-------------- ---------------- ----------------\n",
      "    Error Rate 0.00289487379651 0.00258044930176\n",
      " Accuracy Rate   0.997105126203   0.997419550698\n",
      "True Positives              0.0  0.0285714285714\n",
      "True Negatives               --              1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0025804493017607772, 0.99741955069823918, 0.028571428571428571, 1.0)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: SVM, linear\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression   Training Set       Test Set    \n",
      "------------------- ---------------- ----------------\n",
      "         Error Rate 0.00468384074941 0.00447783849423\n",
      "      Accuracy Rate   0.995316159251   0.995522161506\n",
      "     True Positives  0.0113636363636  0.0857142857143\n",
      "     True Negatives               --   0.997945361845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0044778384942319371,\n",
       " 0.99552216150576811,\n",
       " 0.085714285714285715,\n",
       " 0.99794536184460847)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: logistic regression\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Naive Bayes     Training Set       Test Set    \n",
      "-------------- ---------------- ----------------\n",
      "    Error Rate 0.00286234712464 0.00265634486946\n",
      " Accuracy Rate   0.997137652875   0.997343655131\n",
      "True Positives              0.0              0.0\n",
      "True Negatives               --              1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0026563448694596234, 0.99734365513054035, 0.0, 1.0)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Perceptron     Training Set       Test Set    \n",
      "-------------- ---------------- ----------------\n",
      "    Error Rate 0.00286234712464 0.00265634486946\n",
      " Accuracy Rate   0.997137652875   0.997343655131\n",
      "True Positives              0.0              0.0\n",
      "True Negatives               --              1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0026563448694596234, 0.99734365513054035, 0.0, 1.0)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='perceptron')\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Perceptron')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excited/Happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43920,)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define y\n",
    "y = totalData.exha.values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excited/Happy Model Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SVM         Training Set      Test Set   \n",
      "-------------- --------------- ---------------\n",
      "    Error Rate 0.0290463179807 0.0311930783242\n",
      " Accuracy Rate  0.970953682019  0.968806921676\n",
      "True Positives             0.0             0.0\n",
      "True Negatives              --             1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.031193078324225864, 0.96880692167577409, 0.0, 1.0)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: SVM, linear\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression   Training Set       Test Set    \n",
      "------------------- ---------------- ----------------\n",
      "         Error Rate  0.0296968514182  0.0318002428658\n",
      "      Accuracy Rate   0.970303148582   0.968199757134\n",
      "     True Positives 0.00111982082867 0.00243309002433\n",
      "     True Negatives               --   0.999294947121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.031800242865816633,\n",
       " 0.96819975713418338,\n",
       " 0.0024330900243309003,\n",
       " 0.99929494712103406)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: logistic regression\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Naive Bayes     Training Set      Test Set   \n",
      "-------------- --------------- ---------------\n",
      "    Error Rate 0.0290463179807 0.0311930783242\n",
      " Accuracy Rate  0.970953682019  0.968806921676\n",
      "True Positives             0.0             0.0\n",
      "True Negatives              --             1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.031193078324225864, 0.96880692167577409, 0.0, 1.0)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Perceptron     Training Set      Test Set   \n",
      "-------------- --------------- ---------------\n",
      "    Error Rate 0.0294366380432 0.0313448694596\n",
      " Accuracy Rate  0.970563361957   0.96865513054\n",
      "True Positives             0.0             0.0\n",
      "True Negatives              --  0.999843321582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.031344869459623559, 0.96865513054037644, 0.0, 0.99984332158245204)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='perceptron')\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Perceptron')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anxious/Sad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43920,)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define y\n",
    "y = totalData.ansa.values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anxious/Sad Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SVM         Training Set      Test Set   \n",
      "-------------- --------------- ---------------\n",
      "    Error Rate 0.0411137132449 0.0374924104432\n",
      " Accuracy Rate  0.958886286755  0.962507589557\n",
      "True Positives             0.0             0.0\n",
      "True Negatives              --             1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.037492410443230116, 0.96250758955676985, 0.0, 1.0)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: SVM, linear\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression   Training Set      Test Set   \n",
      "------------------- --------------- ---------------\n",
      "         Error Rate 0.0412438199323 0.0374924104432\n",
      "      Accuracy Rate  0.958756180068  0.962507589557\n",
      "     True Positives             0.0             0.0\n",
      "     True Negatives              --             1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.037492410443230116, 0.96250758955676985, 0.0, 1.0)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: logistic regression\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Naive Bayes     Training Set      Test Set   \n",
      "-------------- --------------- ---------------\n",
      "    Error Rate 0.0411137132449 0.0374924104432\n",
      " Accuracy Rate  0.958886286755  0.962507589557\n",
      "True Positives             0.0             0.0\n",
      "True Negatives              --             1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.037492410443230116, 0.96250758955676985, 0.0, 1.0)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Perceptron     Training Set      Test Set   \n",
      "-------------- --------------- ---------------\n",
      "    Error Rate 0.0411137132449 0.0374924104432\n",
      " Accuracy Rate  0.958886286755  0.962507589557\n",
      "True Positives             0.0             0.0\n",
      "True Negatives              --             1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.037492410443230116, 0.96250758955676985, 0.0, 1.0)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='perceptron')\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Perceptron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
